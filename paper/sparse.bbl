\begin{thebibliography}{10}

\bibitem{Bergstra2012}
J.~Bergstra and Y.~Bengio, ``{Random Search For HyperParameter Optimization},''
  vol.~13, pp.~281--305, 2012.

\bibitem{Zoph2016}
B.~Zoph and Q.~V. Le, ``{Neural Architecture Search with Reinforcement
  Learning},'' pp.~1--16, 2016.

\bibitem{Zoph2018}
B.~Zoph, V.~Vasudevan, J.~Shlens, and Q.~V. Le, ``{Learning Transferable
  Architectures for Scalable Image Recognition},'' {\em Proc. IEEE Comput. Soc.
  Conf. Comput. Vis. Pattern Recognit.}, pp.~8697--8710, 2018.

\bibitem{Mockus1978}
J.~Mockus, V.~Tiesis, and A.~Zilinskas, ``{The application of Bayesian methods
  for seeking the extremum},'' {\em Towar. Glob. Optim.}, vol.~2, no.~September
  2014, pp.~117--129, 1978.

\bibitem{Frazier2018}
P.~I. Frazier, ``{A Tutorial on Bayesian Optimization},'' no.~Section 5,
  pp.~1--22, 2018.

\bibitem{Swersky2014}
K.~Swersky, D.~Duvenaud, J.~Snoek, F.~Hutter, and M.~A. Osborne, ``{Raiders of
  the Lost Architecture: Kernels for Bayesian Optimization in Conditional
  Parameter Spaces},'' pp.~1--6, 2014.

\bibitem{Han2015}
S.~Han, H.~Mao, and W.~J. Dally, ``{Deep Compression: Compressing Deep Neural
  Networks with Pruning, Trained Quantization and Huffman Coding},'' pp.~1--14,
  2015.

\bibitem{Cun:1990:OBD:109230.109298}
Y.~L. Cun, J.~S. Denker, and S.~A. Solla, ``Advances in neural information
  processing systems 2,'' ch.~Optimal Brain Damage, pp.~598--605, San
  Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1990.

\bibitem{Jacob2017}
B.~Jacob, S.~Kligys, B.~Chen, M.~Zhu, M.~Tang, A.~Howard, H.~Adam, and
  D.~Kalenichenko, ``{Quantization and Training of Neural Networks for
  Efficient Integer-Arithmetic-Only Inference},'' 2017.

\bibitem{Howard2017}
A.~G. Howard, M.~Zhu, B.~Chen, D.~Kalenichenko, W.~Wang, T.~Weyand,
  M.~Andreetto, and H.~Adam, ``{MobileNets: Efficient Convolutional Neural
  Networks for Mobile Vision Applications},'' 2017.

\bibitem{TFLite}
``{Tensorflow Lite}.'' \url{https://www.tensorflow.org/lite}.
\newblock Accessed: 2019-07-19.

\bibitem{Rotem2018}
N.~Rotem, J.~Fix, S.~Abdulrasool, G.~Catron, S.~Deng, R.~Dzhabarov, N.~Gibson,
  J.~Hegeman, M.~Lele, R.~Levenstein, J.~Montgomery, B.~Maher, S.~Nadathur,
  J.~Olesen, J.~Park, A.~Rakhov, M.~Smelyanskiy, and M.~Wang, ``{Glow: Graph
  Lowering Compiler Techniques for Neural Networks},'' 2018.

\bibitem{ARMNN}
``{ARM NN}.''
  \url{https://developer.arm.com/ip-products/processors/machine-learning/arm-nn}.
\newblock Accessed: 2019-07-19.

\bibitem{TensorRT}
``{NVIDIA} tensor rt.'' \url{https://developer.nvidia.com/tensorrt}.
\newblock Accessed: 2019-07-19.

\bibitem{uTensor}
``{uTensor}.'' \url{https://github.com/uTensor/uTensor}.
\newblock Accessed: 2020-04-20.

\bibitem{K.O.2002}
S.~K.O. and M.~R., ``{Evolving neural networks through augmenting
  topologies},'' {\em Evol. Comput.}, vol.~10, no.~2, pp.~99--127, 2002.

\bibitem{Elsken2018}
T.~Elsken, J.~H. Metzen, and F.~Hutter, ``{Efficient Multi-objective Neural
  Architecture Search via Lamarckian Evolution},'' pp.~1--23, 2018.

\bibitem{Fedorov2019}
I.~Fedorov, R.~P. Adams, M.~Mattina, and P.~N. Whatmough, ``{SpArSe: Sparse
  Architecture Search for CNNs on Resource-Constrained Microcontrollers},''
  pp.~1--26, 2019.

\bibitem{Loni2020}
M.~Loni, S.~Sinaei, A.~Zoljodi, M.~Daneshtalab, and M.~Sj{\"{o}}din,
  ``{DeepMaker: A multi-objective optimization framework for deep neural
  networks in embedded systems},'' {\em Microprocess. Microsyst.}, vol.~73,
  p.~102989, 2020.

\bibitem{Cai2019f}
H.~Cai, C.~Gan, T.~Wang, Z.~Zhang, and S.~Han, ``{Once-for-All: Train One
  Network and Specialize it for Efficient Deployment on Diverse Hardware
  Platforms},'' pp.~1--13, 2019.

\bibitem{Li2018n}
E.~Li, Z.~Zhou, and X.~Chen, ``{Edge intelligence: On-demand deep learning
  model co-inference with device-edge synergy},'' {\em MECOMM 2018 - Proc. 2018
  Work. Mob. Edge Commun. Part SIGCOMM 2018}, pp.~31--36, 2018.

\bibitem{Lu2019}
B.~Lu, J.~Yang, L.~Y. Chen, and S.~Ren, ``{Automating deep neural network model
  selection for edge inference},'' {\em Proc. - 2019 IEEE 1st Int. Conf. Cogn.
  Mach. Intell. CogMI 2019}, pp.~184--193, 2019.

\bibitem{Jung2014}
M.~M. Jung, R.~Poppe, M.~Poel, and D.~K. Heylen, ``{Touching the void -
  introducing CoST: Corpus of social touch},'' {\em ICMI 2014 - Proc. 2014 Int.
  Conf. Multimodal Interact.}, pp.~120--127, 2014.

\bibitem{Elsken2019a}
T.~Elsken, J.~H. Metzen, and F.~Hutter, ``{Neural Architecture Search},''
  vol.~20, pp.~63--77, 2019.

\bibitem{Wang2019a}
Y.~Wang, Y.~Yang, Y.~Chen, J.~Bai, C.~Zhang, G.~Su, X.~Kou, Y.~Tong, M.~Yang,
  and L.~Zhou, ``{TextNAS: A Neural Architecture Search Space tailored for Text
  Representation},'' 2019.

\bibitem{Xie2017}
L.~Xie and A.~Yuille, ``{Genetic CNN},'' {\em Proc. IEEE Int. Conf. Comput.
  Vis.}, vol.~2017-Octob, pp.~1388--1397, 2017.

\bibitem{Stanley2002}
K.~O. Stanley and R.~Miikkulainen, ``{Evolving neural networks through
  augmenting topologies},'' {\em Evol. Comput.}, vol.~10, no.~2, pp.~99--127,
  2002.

\bibitem{Zhou2019a}
H.~Zhou, M.~Yang, J.~Wang, and W.~Pan, ``{BayesNAS: A Bayesian Approach for
  Neural Architecture Search},'' 2019.

\bibitem{Baker2016}
B.~Baker, O.~Gupta, N.~Naik, and R.~Raskar, ``{Designing Neural Network
  Architectures using Reinforcement Learning},'' pp.~1--18, 2016.

\bibitem{Branke2017}
J.~Branke, ``{Evolutionary algorithms in neural network design and training},''
  no.~September, 1995.

\bibitem{Chu2019}
X.~Chu, B.~Zhang, R.~Xu, and H.~Ma, ``{Multi-Objective Reinforced Evolution in
  Mobile Neural Architecture Search},'' 2019.

\bibitem{Gordon2017}
A.~Gordon, E.~Eban, O.~Nachum, B.~Chen, and T.-J. Yang, ``{FluidNets: Fast {\&}
  Simple Resource-Constrained Structure Learning of Deep Networks},'' no.~1,
  pp.~1586--1595, 2017.

\bibitem{Frankle2019}
J.~Frankle and M.~Carbin, ``{The lottery ticket hypothesis: Finding sparse,
  trainable neural networks},'' {\em 7th Int. Conf. Learn. Represent. ICLR
  2019}, pp.~1--42, 2019.

\bibitem{Elsken2019b}
T.~Elsken, J.~H. Metzen, and F.~Hutter, ``{Neural Architecture Search},''
  vol.~20, pp.~63--77, 2019.

\bibitem{Shahriari2016}
B.~Shahriari, K.~Swersky, Z.~Wang, R.~P. Adams, and N.~{De Freitas}, ``{Taking
  the human out of the loop: A review of Bayesian optimization},'' {\em Proc.
  IEEE}, vol.~104, no.~1, pp.~148--175, 2016.

\bibitem{Shahriari2014}
B.~Shahriari, Z.~Wang, M.~W. Hoffman, A.~Bouchard-C{\^{o}}t{\'{e}}, and
  N.~de~Freitas, ``{An Entropy Search Portfolio for Bayesian Optimization},''
  pp.~1--10, 2014.

\bibitem{Jose2013}
C.~Jose, P.~Goyal, P.~Aggrwal, and M.~Varma, ``{Local deep kernel learning for
  efficient non-linear SVM prediction},'' {\em 30th Int. Conf. Mach. Learn.
  ICML 2013}, vol.~28, no.~PART 2, pp.~1523--1531, 2013.

\bibitem{Hughes2017}
D.~Hughes, A.~Krauthammer, and N.~Correli, ``{Recognizing social touch gestures
  using recurrent and convolutional neural networks},'' {\em Proc. - IEEE Int.
  Conf. Robot. Autom.}, pp.~2315--2321, 2017.

\bibitem{Jung2015}
M.~M. Jung, X.~L. Cang, M.~Poel, and K.~E. Maclean, ``{Touch challenge'15:
  Recognizing social touch gestures},'' {\em ICMI 2015 - Proc. 2015 ACM Int.
  Conf. Multimodal Interact.}, pp.~387--390, 2015.

\bibitem{Ta2015a}
V.~C. Ta, W.~Johal, M.~Portaz, E.~Castelli, and D.~Vaufreydaz, ``{The grenoble
  system for the social touch challenge at ICMI 2015},'' {\em ICMI 2015 - Proc.
  2015 ACM Int. Conf. Multimodal Interact.}, no.~November, pp.~391--398, 2015.

\bibitem{Albawi2018}
S.~Albawi, O.~Bayat, S.~Al-Azawi, and O.~N. Ucan, ``{Social touch gesture
  recognition using convolutional neural network},'' {\em Comput. Intell.
  Neurosci.}, vol.~2018, 2018.

\bibitem{Jung2017}
M.~M. Jung, M.~Poel, R.~Poppe, and D.~K. Heylen, ``{Automatic recognition of
  touch gestures in the corpus of social touch},'' {\em J. Multimodal User
  Interfaces}, vol.~11, no.~1, pp.~81--96, 2017.

\bibitem{Bakshy2018a}
E.~Bakshy, L.~Dworkin, B.~Karrer, K.~Kashin, B.~Letham, A.~Murthy, and
  S.~Singh, ``{AE: A domain-agnostic platform for adaptive experimentation},''
  {\em Conf. Neural Inf. Process. Syst.}, pp.~1--8, 2018.

\bibitem{Balandat2019}
M.~Balandat, B.~Karrer, D.~R. Jiang, S.~Daulton, B.~Letham, A.~G. Wilson, and
  E.~Bakshy, ``{BoTorch: Programmable Bayesian Optimization in PyTorch},''
  2019.

\bibitem{Gardner2018}
J.~R. Gardner, G.~Pleiss, D.~Bindel, K.~Q. Weinberger, and A.~G. Wilson,
  ``{Gpytorch: Blackbox matrix-matrix Gaussian process inference with GPU
  acceleration},'' {\em Adv. Neural Inf. Process. Syst.}, vol.~2018-Decem,
  no.~NeurIPS, pp.~7576--7586, 2018.

\end{thebibliography}
