Automatically generated by Mendeley Desktop 1.19.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Pham2018,
abstract = {We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. ENAS constructs a large computational graph, where each subgraph represents a neural network architecture, hence forcing all architectures to share their parameters. A controller is trained with policy gradient to search for a subgraph that maximizes the expected reward on a validation set. Meanwhile a model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Sharing parameters among child models allows ENAS to deliver strong empirical performances, whilst using much fewer GPU-hours than existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On Penn Treebank, ENAS discovers a novel architecture that achieves a test perplexity of 56.3, on par with the existing state-of-the-art among all methods without post-training processing. On CIFAR-10, ENAS finds a novel architecture that achieves 2.89{\%} test error, which is on par with the 2.65{\%} test error of NASNet (Zoph et al., 2018).},
archivePrefix = {arXiv},
arxivId = {1802.03268},
author = {Pham, Hieu and Guan, Melody Y. and Zoph, Barret and Le, Quoc V. and Dean, Jeff},
eprint = {1802.03268},
file = {:home/kostal/Downloads/1802.03268.pdf:pdf},
isbn = {9781510867963},
journal = {35th Int. Conf. Mach. Learn. ICML 2018},
pages = {6522--6531},
title = {{Efficient Neural Architecture Search via parameter Sharing}},
volume = {9},
year = {2018}
}
@article{Kumar2017a,
abstract = {This paper develops a novel tree-based algorithm, called Bonsai, for efficient prediction on IoT devices â€“ such as those based on the Arduino Uno board having an 8 bit ATmega328P microcontroller operating at 16 MHz with no native floating point support, 2 KB RAM and 32 KB read-only flash. Bonsai maintains prediction accuracy while minimizing model size and prediction costs by: (a) developing a tree model which learns a single, shallow, sparse tree with powerful nodes; (b) sparsely projecting all data into a low-dimensional space in which the tree is learnt; and (c) jointly learning all tree and projection parameters. Experimental results on multiple benchmark datasets demonstrate that Bonsai can make predictions in milliseconds even on slow microcontrollers, can fit in KB of memory, has lower battery consumption than all other algorithms while achieving prediction accuracies that can be as much as 30{\%} higher than state-of-the-art methods for resource-efficient machine learning. Bonsai is also shown to generalize to other resource constrained settings beyond IoT by generating significantly better search results as compared to Bing's L3 ranker when the model size is restricted to 300 bytes. Bonsai's code can be downloaded from (http://www.manikvarma.org/code/Bonsai/download.html).},
author = {Kumar, Ashish and Goyal, Saurabh and Varma, Manik},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Goyal, Varma - 2017 - Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things.pdf:pdf},
journal = {34th Int. Conf. Mach. Learn. (ICML 2017)},
pages = {1935--1944},
title = {{Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things}},
url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/kumar17.pdf{\%}0Ahttp://proceedings.mlr.press/v70/kumar17a.html},
volume = {70},
year = {2017}
}
@article{Miguel2018,
author = {Carreira-Perpi{\~{n}}{\'{a}}n, M. and Idelbayev, Y.},
doi = {10.1109/CVPR.2018.00890},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miguel - 2018 - Learning-Compression Algorithms for Neural Net Pruning (Supplementary material).pdf:pdf},
number = {Lc},
pages = {8532--8541},
title = {{Learning-Compression Algorithms for Neural Net Pruning}},
year = {2018}
}
@article{Brochu2010,
abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
archivePrefix = {arXiv},
arxivId = {1012.2599},
author = {Brochu, Eric and Cora, Vlad M. and de Freitas, Nando},
eprint = {1012.2599},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brochu, Cora, de Freitas - 2010 - A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Model.pdf:pdf},
title = {{A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning}},
url = {http://arxiv.org/abs/1012.2599},
year = {2010}
}
@article{Shahriari2016,
abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and {De Freitas}, Nando},
doi = {10.1109/JPROC.2015.2494218},
issn = {00189219},
journal = {Proc. IEEE},
keywords = {decision making,design of experiments,genomic medicine,optimization,response surface methodology,statistical learning},
number = {1},
pages = {148--175},
publisher = {IEEE},
title = {{Taking the human out of the loop: A review of Bayesian optimization}},
volume = {104},
year = {2016}
}
@article{Jacob2017,
abstract = {The rising popularity of intelligent mobile devices and the daunting computational cost of deep learning-based models call for efficient and accurate on-device inference schemes. We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware. We also co-design a training procedure to preserve end-to-end model accuracy post quantization. As a result, the proposed quantization scheme improves the tradeoff between accuracy and on-device latency. The improvements are significant even on MobileNets, a model family known for run-time efficiency, and are demonstrated in ImageNet classification and COCO detection on popular CPUs.},
archivePrefix = {arXiv},
arxivId = {1712.05877},
author = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
doi = {10.1186/1475-2840-12-70},
eprint = {1712.05877},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jacob et al. - 2017 - Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference.pdf:pdf},
isbn = {1475-2840 (Electronic) 1475-2840 (Linking)},
issn = {0036-8075},
pmid = {23617452},
title = {{Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference}},
url = {http://arxiv.org/abs/1712.05877},
year = {2017}
}
@article{Ku2019,
abstract = {The capability of recognizing various social touch patterns is necessary for robots functioning for touch-based social interaction, which is effective in many robot applications. Literature has focused on the novelty of the recognition system or improvements in classification accuracy based on publicly available datasets. In this paper, we propose an integrated framework of implementing social touch recognition system for various robots, which consists of three complementary principles: 1) multi-modal tactile sensing, 2) a modular design, and 3) a social touch pattern classifier capable of learning temporal features. The approach is evaluated by an implemented Multi-modal-sensing Modular Tactile Interface prototype, while for the classifiers, three learning methods - HMM, LSTM, and 3D-CNN - have been tested. The trained classifiers, which can run online in robot's embedded system, predict 18 classes of social touch pattern. Results of the online validation test offer that all three methods are promising with the best accuracy of 88.86{\%}. Especially, the stable performance of 3D-CNN indicates that learning 'spatiotemporal' features from tactile data would be more effective. Through this validation process, we have confirmed that our framework can be easily adopted and secures robust performance for social touch pattern recognition.},
author = {Ku, Hyun Jin and Choi, Jason J. and Jang, Sunho and Do, Wonkyung and Lee, Soomin and Seok, Sangok},
doi = {10.1109/URAI.2019.8768706},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ku et al. - 2019 - Online Social Touch Pattern Recognition with Multi-modal-sensing Modular Tactile Interface.pdf:pdf},
isbn = {9781728132327},
journal = {2019 16th Int. Conf. Ubiquitous Robot. UR 2019},
pages = {271--277},
publisher = {IEEE},
title = {{Online Social Touch Pattern Recognition with Multi-modal-sensing Modular Tactile Interface}},
year = {2019}
}
@article{Elsken2019b,
abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
archivePrefix = {arXiv},
arxivId = {arXiv:1808.05377v3},
author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
doi = {10.1007/978-3-030-05318-5_3},
eprint = {arXiv:1808.05377v3},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elsken, Metzen, Hutter - 2019 - Neural Architecture Search.pdf:pdf},
keywords = {autodl,automl,neural architecture search,performance estimation strategy,search,search space design,strategy},
pages = {63--77},
title = {{Neural Architecture Search}},
volume = {20},
year = {2019}
}
@article{Snoek2012a,
abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a "black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
archivePrefix = {arXiv},
arxivId = {1206.2944},
author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
eprint = {1206.2944},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Snoek, Larochelle, Adams - 2012 - Practical Bayesian Optimization of Machine Learning Algorithms.pdf:pdf},
month = {jun},
title = {{Practical Bayesian Optimization of Machine Learning Algorithms}},
url = {http://arxiv.org/abs/1206.2944},
year = {2012}
}
@article{Elsken2018,
abstract = {Neural Architecture Search aims at automatically finding neural architectures that are competitive with architectures designed by human experts. While recent approaches have achieved state-of-the-art predictive performance for image recognition, they are problematic under resource constraints for two reasons: (1)the neural architectures found are solely optimized for high predictive performance, without penalizing excessive resource consumption, (2) most architecture search methods require vast computational resources. We address the first shortcoming by proposing LEMONADE, an evolutionary algorithm for multi-objective architecture search that allows approximating the entire Pareto-front of architectures under multiple objectives, such as predictive performance and number of parameters, in a single run of the method. We address the second shortcoming by proposing a Lamarckian inheritance mechanism for LEMONADE which generates children networks that are warmstarted with the predictive performance of their trained parents. This is accomplished by using (approximate) network morphism operators for generating children. The combination of these two contributions allows finding models that are on par or even outperform both hand-crafted as well as automatically-designed networks.},
archivePrefix = {arXiv},
arxivId = {1804.09081},
author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
eprint = {1804.09081},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elsken, Metzen, Hutter - 2018 - Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution.pdf:pdf},
pages = {1--23},
title = {{Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution}},
year = {2018}
}
@article{Letham2019,
abstract = {Randomized experiments are the gold standard for evaluating the effects of changes to real-world systems. Data in these tests may be difficult to collect and outcomes may have high variance, resulting in potentially large measurement error. Bayesian optimization is a promising technique for efficiently optimizing multiple continuous parameters, but existing approaches degrade in performance when the noise level is high, limiting its applicability to many randomized experiments. We derive an expression for expected improvement under greedy batch optimization with noisy observations and noisy constraints, and develop a quasi-Monte Carlo approximation that allows it to be efficiently optimized. Simulations with synthetic functions show that optimization performance on noisy, constrained problems outperforms existing methods. We further demonstrate the effectiveness of the method with two real-world experiments conducted at Facebook: optimizing a ranking system, and optimizing server compiler flags.},
author = {Letham, Benjamin and Karrer, Brian and Ottoni, Guilherme and Bakshy, Eytan},
doi = {10.1214/18-BA1110},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Letham et al. - 2019 - Constrained Bayesian optimization with noisy experiments.pdf:pdf},
issn = {19316690},
journal = {Bayesian Anal.},
keywords = {Bayesian optimization,Quasi-Monte Carlo methods,Randomized experiments},
number = {2},
pages = {495--519},
title = {{Constrained Bayesian optimization with noisy experiments}},
volume = {14},
year = {2019}
}
@article{Elsken2019a,
abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
archivePrefix = {arXiv},
arxivId = {arXiv:1808.05377v3},
author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
doi = {10.1007/978-3-030-05318-5_3},
eprint = {arXiv:1808.05377v3},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elsken, Metzen, Hutter - 2019 - Neural Architecture Search.pdf:pdf},
keywords = {autodl,automl,neural architecture search,performance estimation strategy,search,search space design,strategy},
pages = {63--77},
title = {{Neural Architecture Search}},
volume = {20},
year = {2019}
}
@article{Courbariaux2014,
abstract = {Multipliers are the most space and power-hungry arithmetic operators of the digital implementation of deep neural networks. We train a set of state-of-the-art neural networks (Maxout networks) on three benchmark datasets: MNIST, CIFAR-10 and SVHN. They are trained with three distinct formats: floating point, fixed point and dynamic fixed point. For each of those datasets and for each of those formats, we assess the impact of the precision of the multiplications on the final error after training. We find that very low precision is sufficient not just for running trained networks but also for training them. For example, it is possible to train Maxout networks with 10 bits multiplications.},
archivePrefix = {arXiv},
arxivId = {1412.7024},
author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
doi = {arXiv: 1412.7024},
eprint = {1412.7024},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Courbariaux, Bengio, David - 2014 - Training deep neural networks with low precision multiplications.pdf:pdf},
isbn = {1872-2075},
issn = {10495258},
number = {Section 5},
pages = {1--10},
title = {{Training deep neural networks with low precision multiplications}},
url = {http://arxiv.org/abs/1412.7024},
year = {2014}
}
@article{Zoph2018,
abstract = {Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (the "NASNet search space") which enables transferability. In our experiments, we search for the best convolutional layer (or "cell") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, named "NASNet architecture". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, NASNet achieves 2.4{\%} error rate, which is state-of-the-art. On ImageNet, NASNet achieves, among the published works, state-of-the-art accuracy of 82.7{\%} top-1 and 96.2{\%} top-5 on ImageNet. Our model is 1.2{\%} better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28{\%} in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74{\%} top-1 accuracy, which is 3.1{\%} better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0{\%} achieving 43.1{\%} mAP on the COCO dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1707.07012v4},
author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
doi = {10.1109/CVPR.2018.00907},
eprint = {arXiv:1707.07012v4},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zoph et al. - 2018 - Learning Transferable Architectures for Scalable Image Recognition.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.},
pages = {8697--8710},
title = {{Learning Transferable Architectures for Scalable Image Recognition}},
year = {2018}
}
@article{Howard2017,
abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
archivePrefix = {arXiv},
arxivId = {1704.04861},
author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
eprint = {1704.04861},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Howard et al. - 2017 - MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications.pdf:pdf},
title = {{MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}},
url = {http://arxiv.org/abs/1704.04861},
year = {2017}
}
@article{Cai2019f,
abstract = {We address the challenging problem of efficient deep learning model deployment across many devices and diverse constraints, from general-purpose hardware to specialized accelerators. Conventional approaches either manually design or use neural architecture search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing {\$}CO{\_}2{\$} emission as much as 5 cars' lifetime) thus unscalable. To reduce the cost, our key idea is to decouple model training from architecture search. To this end, we propose to train a once-for-all network (OFA) that supports diverse architectural settings (depth, width, kernel size, and resolution). Given a deployment scenario, we can then quickly get a specialized sub-network by selecting from the OFA network without additional training. To prevent interference between many sub-networks during training, we also propose a novel progressive shrinking algorithm, which can train a surprisingly large number of sub-networks ({\$}{\textgreater} 10{\^{}}{\{}19{\}}{\$}) simultaneously. Extensive experiments on various hardware platforms (CPU, GPU, mCPU, mGPU, FPGA accelerator) show that OFA consistently outperforms SOTA NAS methods (up to 4.0{\%} ImageNet top1 accuracy improvement over MobileNetV3) while reducing orders of magnitude GPU hours and {\$}CO{\_}2{\$} emission. In particular, OFA achieves a new SOTA 80.0{\%} ImageNet top1 accuracy under the mobile setting ({\$}{\textless}{\$}600M FLOPs). Code and pre-trained models are released at https://github.com/mit-han-lab/once-for-all.},
archivePrefix = {arXiv},
arxivId = {1908.09791},
author = {Cai, Han and Gan, Chuang and Wang, Tianzhe and Zhang, Zhekai and Han, Song},
eprint = {1908.09791},
file = {:home/kostal/Downloads/1908.09791.pdf:pdf},
pages = {1--13},
title = {{Once-for-All: Train One Network and Specialize it for Efficient Deployment on Diverse Hardware Platforms}},
url = {http://arxiv.org/abs/1908.09791},
year = {2019}
}
@article{Bergstra2013,
abstract = {Sequential model-based optimization (also known as Bayesian op- timization) is one of the most efficient methods (per function evaluation) of function minimization. This efficiency makes it appropriate for optimizing the hyperparameters of machine learning algorithms that are slow to train. The Hyperopt library provides algorithms and parallelization infrastructure for per- forming hyperparameter optimization (model selection) in Python. This paper presents an introductory tutorial on the usage of the Hyperopt library, including the description of search spaces, minimization (in serial and parallel), and the analysis of the results collected in the course of minimization. The paper closes with some discussion of ongoing and future work.},
author = {Bergstra, James and Yamins, Dan and Cox, David D},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergstra, Yamins, Cox - 2013 - Hyperopt A python library for optimizing the hyperparameters of machine learning algorithms.pdf:pdf},
journal = {12th PYTHON Sci. CONF. (SCIPY 2013)},
number = {Scipy},
pages = {13--20},
title = {{Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms}},
url = {http://hyperopt.github.io/hyperopt/{\%}5Cnhttps://github.com/jaberg/hyperopt{\%}5Cnhttp://www.youtube.com/watch?v=Mp1xnPfE4PY},
year = {2013}
}
@article{Shahriari2014,
abstract = {Bayesian optimization is a sample-efficient method for black-box global optimization. How- ever, the performance of a Bayesian optimization method very much depends on its exploration strategy, i.e. the choice of acquisition function, and it is not clear a priori which choice will result in superior performance. While portfolio methods provide an effective, principled way of combining a collection of acquisition functions, they are often based on measures of past performance which can be misleading. To address this issue, we introduce the Entropy Search Portfolio (ESP): a novel approach to portfolio construction which is motivated by information theoretic considerations. We show that ESP outperforms existing portfolio methods on several real and synthetic problems, including geostatistical datasets and simulated control tasks. We not only show that ESP is able to offer performance as good as the best, but unknown, acquisition function, but surprisingly it often gives better performance. Finally, over a wide range of conditions we find that ESP is robust to the inclusion of poor acquisition functions.},
archivePrefix = {arXiv},
arxivId = {1406.4625},
author = {Shahriari, Bobak and Wang, Ziyu and Hoffman, Matthew W. and Bouchard-C{\^{o}}t{\'{e}}, Alexandre and de Freitas, Nando},
eprint = {1406.4625},
pages = {1--10},
title = {{An Entropy Search Portfolio for Bayesian Optimization}},
url = {http://arxiv.org/abs/1406.4625},
year = {2014}
}
@article{Li2018i,
abstract = {This paper introduces a filter level pruning method based on similar feature extraction for compressing and accelerating the convolutional neural networks by k-means++ algorithm. In contrast to other pruning methods, the proposed method would analyze the similarities in recognizing features among filters rather than evaluate the importance of filters to prune the redundant ones. This strategy would be more reasonable and effective. Furthermore, our method does not result in unstructured network. As a result, it needs not extra sparse representation and could be efficiently supported by any off-The-shelf deep learning libraries. Experimental results show that our filter pruning method could reduce the number of parameters and the amount of computational costs in Lenet-5 by a factor of 17.9Ã— with only 0.3{\%} accuracy loss.},
author = {Li, Lianqiang and Xu, Yuhui and Zhu, Jie},
doi = {10.1587/transinf.2017EDL8248},
file = {::},
issn = {17451361},
journal = {IEICE Trans. Inf. Syst.},
keywords = {Cnns,Feature extraction,Filter,K-Means++,Pruning,Structured},
number = {4},
pages = {1203--1206},
title = {{Filter level pruning based on similar feature extraction for convolutional neural networks}},
volume = {E101D},
year = {2018}
}
@article{Cai2019f,
abstract = {We address the challenging problem of efficient deep learning model deployment across many devices and diverse constraints, from general-purpose hardware to specialized accelerators. Conventional approaches either manually design or use neural architecture search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing {\$}CO{\_}2{\$} emission as much as 5 cars' lifetime) thus unscalable. To reduce the cost, our key idea is to decouple model training from architecture search. To this end, we propose to train a once-for-all network (OFA) that supports diverse architectural settings (depth, width, kernel size, and resolution). Given a deployment scenario, we can then quickly get a specialized sub-network by selecting from the OFA network without additional training. To prevent interference between many sub-networks during training, we also propose a novel progressive shrinking algorithm, which can train a surprisingly large number of sub-networks ({\$}{\textgreater} 10{\^{}}{\{}19{\}}{\$}) simultaneously. Extensive experiments on various hardware platforms (CPU, GPU, mCPU, mGPU, FPGA accelerator) show that OFA consistently outperforms SOTA NAS methods (up to 4.0{\%} ImageNet top1 accuracy improvement over MobileNetV3) while reducing orders of magnitude GPU hours and {\$}CO{\_}2{\$} emission. In particular, OFA achieves a new SOTA 80.0{\%} ImageNet top1 accuracy under the mobile setting ({\$}{\textless}{\$}600M FLOPs). Code and pre-trained models are released at https://github.com/mit-han-lab/once-for-all.},
archivePrefix = {arXiv},
arxivId = {1908.09791},
author = {Cai, Han and Gan, Chuang and Wang, Tianzhe and Zhang, Zhekai and Han, Song},
eprint = {1908.09791},
file = {:home/kostal/Downloads/1908.09791.pdf:pdf},
pages = {1--13},
title = {{Once-for-All: Train One Network and Specialize it for Efficient Deployment on Diverse Hardware Platforms}},
url = {http://arxiv.org/abs/1908.09791},
year = {2019}
}
@article{Frankle2019,
abstract = {Neural network pruning techniques can reduce the parameter counts of trained networks by over 90{\%}, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the lottery ticket hypothesis: dense, randomly-initialized, feed-forward networks contain subnetworks (winning tickets) that-when trained in isolation-reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20{\%} of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.},
archivePrefix = {arXiv},
arxivId = {1803.03635},
author = {Frankle, Jonathan and Carbin, Michael},
eprint = {1803.03635},
journal = {7th Int. Conf. Learn. Represent. ICLR 2019},
pages = {1--42},
title = {{The lottery ticket hypothesis: Finding sparse, trainable neural networks}},
year = {2019}
}
@article{Zhou2019a,
abstract = {One-Shot Neural Architecture Search (NAS) is a promising method to significantly reduce search time without any separate training. It can be treated as a Network Compression problem on the architecture parameters from an over-parameterized network. However, there are two issues associated with most one-shot NAS methods. First, dependencies between a node and its predecessors and successors are often disregarded which result in improper treatment over zero operations. Second, architecture parameters pruning based on their magnitude is questionable. In this paper, we employ the classic Bayesian learning approach to alleviate these two issues by modeling architecture parameters using hierarchical automatic relevance determination (HARD) priors. Unlike other NAS methods, we train the over-parameterized network for only one epoch then update the architecture. Impressively, this enabled us to find the architecture on CIFAR-10 within only 0.2 GPU days using a single GPU. Competitive performance can be also achieved by transferring to ImageNet. As a byproduct, our approach can be applied directly to compress convolutional neural networks by enforcing structural sparsity which achieves extremely sparse networks without accuracy deterioration.},
archivePrefix = {arXiv},
arxivId = {1905.04919},
author = {Zhou, Hongpeng and Yang, Minghao and Wang, Jun and Pan, Wei},
eprint = {1905.04919},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2019 - BayesNAS A Bayesian Approach for Neural Architecture Search.pdf:pdf},
title = {{BayesNAS: A Bayesian Approach for Neural Architecture Search}},
url = {http://arxiv.org/abs/1905.04919},
year = {2019}
}
@article{Fedorov2019,
abstract = {The vast majority of processors in the world are actually microcontroller units (MCUs), which find widespread use performing simple control tasks in applications ranging from automobiles to medical devices and office equipment. The Internet of Things (IoT) promises to inject machine learning into many of these every-day objects via tiny, cheap MCUs. However, these resource-impoverished hardware platforms severely limit the complexity of machine learning models that can be deployed. For example, although convolutional neural networks (CNNs) achieve state-of-the-art results on many visual recognition tasks, CNN inference on MCUs is challenging due to severe finite memory limitations. To circumvent the memory challenge associated with CNNs, various alternatives have been proposed that do fit within the memory budget of an MCU, albeit at the cost of prediction accuracy. This paper challenges the idea that CNNs are not suitable for deployment on MCUs. We demonstrate that it is possible to automatically design CNNs which generalize well, while also being small enough to fit onto memory-limited MCUs. Our Sparse Architecture Search method combines neural architecture search with pruning in a single, unified approach, which learns superior models on four popular IoT datasets. The CNNs we find are more accurate and up to {\$}4.35\backslashtimes{\$} smaller than previous approaches, while meeting the strict MCU working memory constraint.},
archivePrefix = {arXiv},
arxivId = {1905.12107},
author = {Fedorov, Igor and Adams, Ryan P. and Mattina, Matthew and Whatmough, Paul N.},
eprint = {1905.12107},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fedorov et al. - 2019 - SpArSe Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers.pdf:pdf},
pages = {1--26},
title = {{SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers}},
url = {http://arxiv.org/abs/1905.12107},
year = {2019}
}
@article{Xie2017,
abstract = {The deep Convolutional Neural Network (CNN) is the state-of-the-art solution for large-scale visual recognition. Following basic principles such as increasing the depth and constructing highway connections, researchers have manually designed a lot of fixed network structures and verified their effectiveness. In this paper, we discuss the possibility of learning deep network structures automatically. Note that the number of possible network structures increases exponentially with the number of layers in the network, which inspires us to adopt the genetic algorithm to efficiently traverse this large search space. We first propose an encoding method to represent each network structure in a fixed-length binary string, and initialize the genetic algorithm by generating a set of randomized individuals. In each generation, we define standard genetic operations, e.g., selection, mutation and crossover, to eliminate weak individuals and then generate more competitive ones. The competitiveness of each individual is defined as its recognition accuracy, which is obtained via training the network from scratch and evaluating it on a validation set. We run the genetic process on two small datasets, i.e., MNIST and CIFAR10, demonstrating its ability to evolve and find high-quality structures which are little studied before. These structures are also transferrable to the large-scale ILSVRC2012 dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.01513v1},
author = {Xie, Lingxi and Yuille, Alan},
doi = {10.1109/ICCV.2017.154},
eprint = {arXiv:1703.01513v1},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie, Yuille - 2017 - Genetic CNN.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proc. IEEE Int. Conf. Comput. Vis.},
pages = {1388--1397},
title = {{Genetic CNN}},
volume = {2017-Octob},
year = {2017}
}
@article{Swersky2014,
abstract = {In practical Bayesian optimization, we must often search over structures with differing numbers of parameters. For instance, we may wish to search over neural network architectures with an unknown number of layers. To relate performance data gathered for different architectures, we define a new kernel for conditional parameter spaces that explicitly includes information about which parameters are relevant in a given structure. We show that this kernel improves model quality and Bayesian optimization results over several simpler baseline kernels.},
archivePrefix = {arXiv},
arxivId = {1409.4011},
author = {Swersky, Kevin and Duvenaud, David and Snoek, Jasper and Hutter, Frank and Osborne, Michael A.},
eprint = {1409.4011},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Swersky et al. - 2014 - Raiders of the Lost Architecture Kernels for Bayesian Optimization in Conditional Parameter Spaces.pdf:pdf},
pages = {1--6},
title = {{Raiders of the Lost Architecture: Kernels for Bayesian Optimization in Conditional Parameter Spaces}},
url = {http://arxiv.org/abs/1409.4011},
year = {2014}
}
@article{Bergstra2011,
abstract = {Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel ap-proaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it pos-sible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neu-ral networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the ex-pected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreli-able for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.},
archivePrefix = {arXiv},
arxivId = {1206.2944},
author = {Bergstra, James and Bardenet, R{\'{e}}mi and Bengio, Yoshua and K{\'{e}}gl, Bal{\'{a}}zs},
doi = {2012arXiv1206.2944S},
eprint = {1206.2944},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergstra et al. - 2011 - Algorithms for Hyper-Parameter Optimization.pdf:pdf},
isbn = {9781618395993},
issn = {10495258},
journal = {Adv. Neural Inf. Process. Syst.},
pages = {2546--2554},
pmid = {9377276},
title = {{Algorithms for Hyper-Parameter Optimization}},
year = {2011}
}
@article{Louizos2017,
abstract = {Compression and computational efficiency in deep learning have become a problem of great significance. In this work, we argue that the most principled and effective way to attack this problem is by adopting a Bayesian point of view, where through sparsity inducing priors we prune large parts of the network. We introduce two novelties in this paper: 1) we use hierarchical priors to prune nodes instead of individual weights, and 2) we use the posterior uncertainties to determine the optimal fixed point precision to encode the weights. Both factors significantly contribute to achieving the state of the art in terms of compression rates, while still staying competitive with methods designed to optimize for speed or energy efficiency.},
archivePrefix = {arXiv},
arxivId = {1705.08665},
author = {Louizos, Christos and Ullrich, Karen and Welling, Max},
eprint = {1705.08665},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Louizos, Ullrich, Welling - 2017 - Bayesian Compression for Deep Learning.pdf:pdf},
number = {Nips},
title = {{Bayesian Compression for Deep Learning}},
url = {http://arxiv.org/abs/1705.08665},
year = {2017}
}
@article{Kusner2014,
abstract = {We present Stochastic Neighbor Compression (SNC), an algorithm to compress a dataset for the purpose of fc-nearest neighbor (fcNN) classification. Given training data, SNC learns a much smaller synthetic data set, that minimizes the stochastic 1-nearest neighbor classification error on the training data. This approach has several appealing properties: due to its small size, the compressed set speeds up fcNN testing drastically (up to several orders of magnitude, in our experiments); it makes the fcNN classifier substantially more robust to label noise; on 4 of 7 data sets it yields lower test error than fcNN on the entire training set, even at compression ratios as low as 2{\%}; finally, the SNC compression leads to impressive speed ups over fcNN even when fcNN and SNC are both used with ball-tree data structures, hashing, and LMNN dimensionality reduction-demonstrating that it is complementary to existing state-of-the-art algorithms to speed up fcNN classification and leads to substantial further improvements.},
author = {Kusner, Matt J. and Tyree, Stephen and Weinberger, Kilian and Agrawal, Kunal},
isbn = {9781634393973},
journal = {31st Int. Conf. Mach. Learn. ICML 2014},
pages = {2051--2059},
title = {{Stochastic neighbor compression}},
volume = {3},
year = {2014}
}
@article{Letham2019a,
abstract = {Online field experiments are the gold-standard way of evaluating changes to real-world interactive machine learning systems. Yet our ability to explore complex, multi-dimensional policy spaces - such as those found in recommendation and ranking problems - is often constrained by the limited number of experiments that can be run simultaneously. To alleviate these constraints, we augment online experiments with an offline simulator and apply multi-task Bayesian optimization to tune live machine learning systems. We describe practical issues that arise in these types of applications, including biases that arise from using a simulator and assumptions for the multi-task kernel. We measure empirical learning curves which show substantial gains from including data from biased offline experiments, and show how these learning curves are consistent with theoretical results for multi-task Gaussian process generalization. We find that improved kernel inference is a significant driver of multi-task generalization. Finally, we show several examples of Bayesian optimization efficiently tuning a live machine learning system by combining offline and online experiments.},
archivePrefix = {arXiv},
arxivId = {1904.01049},
author = {Letham, Benjamin and Bakshy, Eytan},
eprint = {1904.01049},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Letham, Bakshy - 2019 - Bayesian Optimization for Policy Search via Online-Offline Experimentation.pdf:pdf},
keywords = {a,b,bayesian optimization,multi-fidelity optimization,multi-task gaussian process,policy search,testing},
number = {0000},
title = {{Bayesian Optimization for Policy Search via Online-Offline Experimentation}},
url = {http://arxiv.org/abs/1904.01049},
volume = {0},
year = {2019}
}
@book{Wang2020,
author = {Wang, An and Liao, Mingxue and Lv, Pin},
doi = {10.1007/978-3-030-32591-6},
file = {::},
isbn = {9783030325916},
keywords = {Dialogue systems,Knowledge selection,Copying mecha,dialogue systems},
pages = {451--458},
title = {{in Pointer-Generator Dialogue Systems}},
url = {http://dx.doi.org/10.1007/978-3-030-32591-6{\_}48},
volume = {2},
year = {2020}
}
@article{Melis2017,
abstract = {Ongoing innovations in recurrent neural network architectures have provided a steady influx of apparently state-of-the-art results on language modelling benchmarks. However, these have been evaluated using differing code bases and limited computational resources, which represent uncontrolled sources of experimental variation. We reevaluate several popular architectures and regularisation methods with large-scale automatic black-box hyperparameter tuning and arrive at the somewhat surprising conclusion that standard LSTM architectures, when properly regularised, outperform more recent models. We establish a new state of the art on the Penn Treebank and Wikitext-2 corpora, as well as strong baselines on the Hutter Prize dataset.},
archivePrefix = {arXiv},
arxivId = {1707.05589},
author = {Melis, G{\'{a}}bor and Dyer, Chris and Blunsom, Phil},
eprint = {1707.05589},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Melis, Dyer, Blunsom - 2017 - On the State of the Art of Evaluation in Neural Language Models.pdf:pdf},
pages = {1--10},
title = {{On the State of the Art of Evaluation in Neural Language Models}},
url = {http://arxiv.org/abs/1707.05589},
year = {2017}
}
@article{Gardner2018,
abstract = {Despite advances in scalable models, the inference tools used for Gaussian processes (GPs) have yet to fully capitalize on developments in computing hardware. We present an efficient and general approach to GP inference based on Blackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modified batched version of the conjugate gradients algorithm to derive all terms for training and inference in a single call. BBMM reduces the asymptotic complexity of exact GP inference from O(n3) to O(n2). Adapting this algorithm to scalable approximations and complex GP models simply requires a routine for efficient matrix-matrix multiplication with the kernel and its derivative. In addition, BBMM uses a specialized preconditioner to substantially speed up convergence. In experiments we show that BBMM effectively uses GPU hardware to dramatically accelerate both exact GP inference and scalable approximations. Additionally, we provide GPyTorch, a software platform for scalable GP inference via BBMM, built on PyTorch.},
archivePrefix = {arXiv},
arxivId = {1809.11165},
author = {Gardner, Jacob R. and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q. and Wilson, Andrew Gordon},
eprint = {1809.11165},
file = {::},
issn = {10495258},
journal = {Adv. Neural Inf. Process. Syst.},
number = {NeurIPS},
pages = {7576--7586},
title = {{Gpytorch: Blackbox matrix-matrix Gaussian process inference with GPU acceleration}},
volume = {2018-Decem},
year = {2018}
}
@article{Gordon2017,
abstract = {We present FluidNets, an approach to automate the design of neural network structures. FluidNets iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers. In contrast to previous approaches, our method is scalable to large networks, adaptable to specific resource constraints (e.g. the number of floating-point operations per inference), and capable of increasing the network's performance. When applied to standard network architectures on a wide variety of datasets, our approach discovers novel structures in each domain, obtaining higher performance while respecting the resource constraint.},
archivePrefix = {arXiv},
arxivId = {1711.06798},
author = {Gordon, Ariel and Eban, Elad and Nachum, Ofir and Chen, Bo and Yang, Tien-Ju},
eprint = {1711.06798},
number = {1},
pages = {1586--1595},
title = {{FluidNets: Fast {\&} Simple Resource-Constrained Structure Learning of Deep Networks}},
url = {http://arxiv.org/abs/1711.06798},
year = {2017}
}
@article{Balandat2019,
abstract = {Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, molecular chemistry, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization. Enabled by Monte-Carlo (MC) acquisition functions and auto-differentiation, BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, radically simplifying implementation of novel acquisition functions. Our MC approach is made practical by a distinctive algorithmic foundation that leverages fast predictive distributions and hardware acceleration. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries. BoTorch is open source and available at https://github.com/pytorch/botorch.},
archivePrefix = {arXiv},
arxivId = {1910.06403},
author = {Balandat, Maximilian and Karrer, Brian and Jiang, Daniel R. and Daulton, Samuel and Letham, Benjamin and Wilson, Andrew Gordon and Bakshy, Eytan},
eprint = {1910.06403},
file = {::},
title = {{BoTorch: Programmable Bayesian Optimization in PyTorch}},
url = {http://arxiv.org/abs/1910.06403},
year = {2019}
}
@article{Zoph2016,
abstract = {Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214.},
archivePrefix = {arXiv},
arxivId = {1611.01578},
author = {Zoph, Barret and Le, Quoc V.},
eprint = {1611.01578},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zoph, Le - 2016 - Neural Architecture Search with Reinforcement Learning.pdf:pdf},
pages = {1--16},
title = {{Neural Architecture Search with Reinforcement Learning}},
url = {http://arxiv.org/abs/1611.01578},
year = {2016}
}
@article{Pham2018,
abstract = {We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. ENAS constructs a large computational graph, where each subgraph represents a neural network architecture, hence forcing all architectures to share their parameters. A controller is trained with policy gradient to search for a subgraph that maximizes the expected reward on a validation set. Meanwhile a model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Sharing parameters among child models allows ENAS to deliver strong empirical performances, whilst using much fewer GPU-hours than existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On Penn Treebank, ENAS discovers a novel architecture that achieves a test perplexity of 56.3, on par with the existing state-of-the-art among all methods without post-training processing. On CIFAR-10, ENAS finds a novel architecture that achieves 2.89{\%} test error, which is on par with the 2.65{\%} test error of NASNet (Zoph et al., 2018).},
archivePrefix = {arXiv},
arxivId = {1802.03268},
author = {Pham, Hieu and Guan, Melody Y. and Zoph, Barret and Le, Quoc V. and Dean, Jeff},
eprint = {1802.03268},
file = {:home/kostal/Downloads/1802.03268.pdf:pdf},
isbn = {9781510867963},
journal = {35th Int. Conf. Mach. Learn. ICML 2018},
pages = {6522--6531},
title = {{Efficient Neural Architecture Search via parameter Sharing}},
volume = {9},
year = {2018}
}
@article{Jung2015,
abstract = {Advances in the field of touch recognition could open up applications for touch-based interaction in areas such as Human-Robot Interaction (HRI). We extended this challenge to the research community working on multimodal interaction with the goal of sparking interest in the touch modality and to promote exploration of the use of data processing techniques from other more mature modalities for touch recognition. Two data sets were made available containing labeled pressure sensor data of social touch gestures that were performed by touching a touch-sensitive surface with the hand. Each set was collected from similar sensor grids, but under conditions reflecting different application orientations: CoST: Corpus of Social Touch and HAART: The Human-Animal Affective Robot Touch gesture set. In this paper we describe the challenge protocol and summarize the results from the touch challenge hosted in conjunction with the 2015 ACM International Conference on Multimodal Interaction (ICMI). The most important outcomes of the challenges were: (1) transferring techniques from other modalities, such as image processing, speech, and human action recognition provided valuable feature sets; (2) gesture classification confusions were similar despite the various data processing methods used.},
author = {Jung, Merel M. and Cang, Xi Laura and Poel, Mannes and Maclean, Karon E.},
doi = {10.1145/2818346.2829993},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jung et al. - 2015 - Touch challenge'15 Recognizing social touch gestures.pdf:pdf},
isbn = {9781450339124},
journal = {ICMI 2015 - Proc. 2015 ACM Int. Conf. Multimodal Interact.},
keywords = {Social touch,Touch data set,Touch gesture recognition},
pages = {387--390},
title = {{Touch challenge'15: Recognizing social touch gestures}},
year = {2015}
}
@article{Jung2014,
abstract = {Touch behavior is of great importance during social interaction. To transfer the tactile modality from interpersonal interaction to other areas such as Human-Robot Interaction (HRI) and remote communication automatic recognition of social touch is necessary. This paper introduces CoST: Corpus of Social Touch, a collection containing 7805 instances of 14 different social touch gestures. The gestures were performed in three variations: gentle, normal and rough, on a sensor grid wrapped around a mannequin arm. Recognition of the rough variations of these 14 gesture classes using Bayesian classiffiers and Support Vector Machines (SVMs) resulted in an overall accuracy of 54{\%} and 53{\%}, respectively. Furthermore, this paper provides more insight into the challenges of automatic recognition of social touch gestures, including which gestures can be recognized more easily and which are more difficult to recognize.},
author = {Jung, Merel M. and Poppe, Ronald and Poel, Mannes and Heylen, Dirk K.J.},
doi = {10.1145/2663204.2663242},
isbn = {9781450328852},
journal = {ICMI 2014 - Proc. 2014 Int. Conf. Multimodal Interact.},
keywords = {Social touch,Touch corpus,Touch gesture recognition},
pages = {120--127},
title = {{Touching the void - introducing CoST: Corpus of social touch}},
year = {2014}
}
@article{Taylor2018a,
abstract = {The recent ground-breaking advances in deep learning networks (DNNs) make them attractive for embedded systems. However, it can take a long time for DNNs to make an inference on resource-limited embedded devices. Offloading the computation into the cloud is often infeasible due to privacy concerns, high latency, or the lack of connectivity. As such, there is a critical need to find a way to effectively execute the DNN models locally on the devices. This paper presents an adaptive scheme to determine which DNN model to use for a given input, by considering the desired accuracy and inference time. Our approach employs machine learning to develop a predictive model to quickly select a pre-trained DNN to use for a given input and the optimization constraint. We achieve this by first training off-line a predictive model, and then use the learnt model to select a DNN model to use for new, unseen inputs. We apply our approach to the image classification task and evaluate it on a Jetson TX2 embedded deep learning platform using the ImageNet ILSVRC 2012 validation dataset. We consider a range of influential DNN models. Experimental results show that our approach achieves a 7.52{\%} improvement in inference accuracy, and a 1.8x reduction in inference time over the most-capable single DNN model.},
archivePrefix = {arXiv},
arxivId = {arXiv:1805.04252v1},
author = {Taylor, Ben and Marco, Vicent Sanz and Wolff, Willy and Elkhatib, Yehia and Wang, Zheng},
doi = {10.1145/3211332.3211336},
eprint = {arXiv:1805.04252v1},
file = {:home/kostal/Downloads/1805.04252.pdf:pdf},
isbn = {9781450358033},
journal = {Proc. ACM SIGPLAN Conf. Lang. Compil. Tools Embed. Syst.},
keywords = {Adaptive computing,Deep learning,Embedded systems},
pages = {31--43},
title = {{Adaptive deep learning model selection on embedded systems}},
volume = {2},
year = {2018}
}
@article{Stanley2002,
abstract = {An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is significantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.},
author = {Stanley, Kenneth O. and Miikkulainen, Risto},
doi = {10.1162/106365602320169811},
file = {:home/kostal/Downloads/stanley.ec02.pdf:pdf},
issn = {10636560},
journal = {Evol. Comput.},
keywords = {Competing conventions,Genetic algorithms,Network topologies,Neural networks,Neuroevolution,Speciation},
number = {2},
pages = {99--127},
pmid = {12180173},
title = {{Evolving neural networks through augmenting topologies}},
volume = {10},
year = {2002}
}
@article{Wang2016e,
abstract = {We consider parallel global optimization of derivative-free expensive-to-evaluate functions, and propose an efficient method based on stochastic approximation for implementing a conceptual Bayesian optimization algorithm proposed by Ginsbourger et al. (2007). At the heart of this algorithm is maximizing the information criterion called the "multi-points expected improvement'', or the q-EI. To accomplish this, we use infinitessimal perturbation analysis (IPA) to construct a stochastic gradient estimator and show that this estimator is unbiased. We also show that the stochastic gradient ascent algorithm using the constructed gradient estimator converges to a stationary point of the q-EI surface, and therefore, as the number of multiple starts of the gradient ascent algorithm and the number of steps for each start grow large, the one-step Bayes optimal set of points is recovered. We show in numerical experiments that our method for maximizing the q-EI is faster than methods based on closed-form evaluation using high-dimensional integration, when considering many parallel function evaluations, and is comparable in speed when considering few. We also show that the resulting one-step Bayes optimal algorithm for parallel global optimization finds high-quality solutions with fewer evaluations than a heuristic based on approximately maximizing the q-EI. A high-quality open source implementation of this algorithm is available in the open source Metrics Optimization Engine (MOE).},
archivePrefix = {arXiv},
arxivId = {1602.05149},
author = {Wang, Jialei and Clark, Scott C. and Liu, Eric and Frazier, Peter I.},
eprint = {1602.05149},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2016 - Parallel Bayesian Global Optimization of Expensive Functions.pdf:pdf},
pages = {1--30},
title = {{Parallel Bayesian Global Optimization of Expensive Functions}},
url = {http://arxiv.org/abs/1602.05149},
year = {2019}
}
@article{Falkner2018,
abstract = {Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. Here, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.},
archivePrefix = {arXiv},
arxivId = {1807.01774},
author = {Falkner, Stefan and Klein, Aaron and Hutter, Frank},
eprint = {1807.01774},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Falkner, Klein, Hutter - 2018 - BOHB Robust and Efficient Hyperparameter Optimization at Scale(3).pdf:pdf},
title = {{BOHB: Robust and Efficient Hyperparameter Optimization at Scale}},
url = {http://arxiv.org/abs/1807.01774},
year = {2018}
}
@article{Branke2017,
author = {Branke, Juergen},
file = {:home/kostal/Downloads/RoteReihe.pdf:pdf},
number = {September},
title = {{Evolutionary algorithms in neural network design and training}},
year = {1995}
}
@article{Ru2019,
abstract = {Efficient optimisation of black-box problems that comprise both continuous and categorical inputs is important, yet poses significant challenges. We propose a new approach, Continuous and Categorical Bayesian Optimisation (CoCaBO), which combines the strengths of multi-armed bandits and Bayesian optimisation to select values for both categorical and continuous inputs. We model this mixed-type space using a Gaussian Process kernel, designed to allow sharing of information across multiple categorical variables, each with multiple possible values; this allows CoCaBO to leverage all available data efficiently. We extend our method to the batch setting and propose an efficient selection procedure that dynamically balances exploration and exploitation whilst encouraging batch diversity. We demonstrate empirically that our method outperforms existing approaches on both synthetic and real-world optimisation tasks with continuous and categorical inputs.},
archivePrefix = {arXiv},
arxivId = {1906.08878},
author = {Ru, Binxin and Alvi, Ahsan S. and Nguyen, Vu and Osborne, Michael A. and Roberts, Stephen J},
eprint = {1906.08878},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ru et al. - 2019 - Bayesian Optimisation over Multiple Continuous and Categorical Inputs.pdf:pdf},
title = {{Bayesian Optimisation over Multiple Continuous and Categorical Inputs}},
url = {http://arxiv.org/abs/1906.08878},
year = {2019}
}
@article{Lu2019,
abstract = {The ever increasing size of deep neural network (DNN) models once implied that they were only limited to cloud data centers for runtime inference. Nonetheless, the recent plethora of DNN model compression techniques have successfully overcome this limit, turning into a reality that DNN-based inference can be run on numerous resource-constrained edge devices including mobile phones, drones, robots, medical devices, wearables, Internet of Things devices, among many others. Naturally, edge devices are highly heterogeneous in terms of hardware specification and usage scenarios. On the other hand, compressed DNN models are so diverse that they exhibit different tradeoffs in a multi-dimension space, and not a single model can achieve optimality in terms of all important metrics such as accuracy, latency and energy consumption. Consequently, how to automatically select a compressed DNN model for an edge device to run inference with optimal quality of experience (QoE) arises as a new challenge. The state-of-the-art approaches either choose a common model for all/most devices, which is optimal for a small fraction of edge devices at best, or apply device-specific DNN model compression, which is not scalable. In this paper, by leveraging the predictive power of machine learning and keeping end users in the loop, we envision an automated device-level DNN model selection engine for QoE-optimal edge inference. To concretize our vision, we formulate the DNN model selection problem into a contextual multi-armed bandit framework, where features of edge devices and DNN models are contexts and pre-trained DNN models are arms selected online based on the history of actions and users' QoE feedback. We develop an efficient online learning algorithm to balance exploration and exploitation. Our preliminary simulation results validate our algorithm and highlight the potential of machine learning for automating DNN model selection to achieve QoE-optimal edge inference.},
author = {Lu, Bingqian and Yang, Jianyi and Chen, Lydia Y. and Ren, Shaolei},
doi = {10.1109/CogMI48466.2019.00035},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2019 - Automating deep neural network model selection for edge inference.pdf:pdf},
isbn = {9781728167374},
journal = {Proc. - 2019 IEEE 1st Int. Conf. Cogn. Mach. Intell. CogMI 2019},
keywords = {Deep neural network,Edge inference,Model selection,Multi arm bandit,Online learning,Quality of experience},
pages = {184--193},
title = {{Automating deep neural network model selection for edge inference}},
year = {2019}
}
@article{Gordon2017b,
abstract = {We present FluidNets, an approach to automate the design of neural network structures. FluidNets iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers. In contrast to previous approaches, our method is scalable to large networks, adaptable to specific resource constraints (e.g. the number of floating-point operations per inference), and capable of increasing the network's performance. When applied to standard network architectures on a wide variety of datasets, our approach discovers novel structures in each domain, obtaining higher performance while respecting the resource constraint.},
archivePrefix = {arXiv},
arxivId = {1711.06798},
author = {Gordon, Ariel and Eban, Elad and Nachum, Ofir and Chen, Bo and Yang, Tien-Ju},
eprint = {1711.06798},
file = {:home/kostal/Downloads/Gordon{\_}MorphNet{\_}Fast{\_}{\_}CVPR{\_}2018{\_}paper.pdf:pdf},
number = {1},
pages = {1586--1595},
title = {{FluidNets: Fast {\&} Simple Resource-Constrained Structure Learning of Deep Networks}},
url = {http://arxiv.org/abs/1711.06798},
year = {2017}
}
@article{Chu2019,
abstract = {Fabricating neural models for a wide range of mobile devices demands for a specific design of networks due to highly constrained resources. Both evolution algorithms (EA) and reinforced learning methods (RL) have been dedicated to solve neural architecture search problems. However, these combinations usually concentrate on a single objective such as the error rate of image classification. They also fail to harness the very benefits from both sides. In this paper, we present a new multi-objective oriented algorithm called MoreMNAS (Multi-Objective Reinforced Evolution in Mobile Neural Architecture Search) by leveraging good virtues from both EA and RL. In particular, we incorporate a variant of multi-objective genetic algorithm NSGA-II, in which the search space is composed of various cells so that crossovers and mutations can be performed at the cell level. Moreover, reinforced control is mixed with a natural mutating process to regulate arbitrary mutation, maintaining a delicate balance between exploration and exploitation. Therefore, not only does our method prevent the searched models from degrading during the evolution process, but it also makes better use of learned knowledge. Our experiments conducted in Super-resolution domain (SR) deliver rivalling models compared to some state-of-the-art methods with fewer FLOPS.},
archivePrefix = {arXiv},
arxivId = {1901.01074},
author = {Chu, Xiangxiang and Zhang, Bo and Xu, Ruijun and Ma, Hailong},
eprint = {1901.01074},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chu et al. - 2019 - Multi-Objective Reinforced Evolution in Mobile Neural Architecture Search.pdf:pdf},
title = {{Multi-Objective Reinforced Evolution in Mobile Neural Architecture Search}},
url = {http://arxiv.org/abs/1901.01074},
year = {2019}
}
@article{Gupta2017,
abstract = {Several real-world applications require real-time prediction on resource-scarce devices such as an Internet of Things (IoT) sensor. Such applications demand prediction models with small storage and computational complexity that do not compromise significantly on accuracy. In this work, we propose ProtoNN, a novel algorithm that addresses the problem of real-time and accurate prediction on resource-scarce devices. ProtoNN is inspired by k-Nearest Neighbor (KNN) but has several orders lower storage and prediction complexity. ProtoNN models can be deployed even on devices with puny storage and computational power (e.g. An Arduino UNO with 2kB RAM) to get excellent prediction accuracy. ProtoNN derives its strength from three key ideas: a) learning a small number of prototypes to represent the entire training set, b) sparse low dimensional projection of data, c) joint discriminative learning of the projection and prototypes with explicit model size constraint. Wc conduct systematic empirical evaluation of ProtoNN on a variety of supervised learning tasks (binary, multi-class, multi-label classification) and show that it gives nearly state-of-the-art prediction ac-curacy on resource-scarce devices while consuming several orders lower storage, and using minimal working memory.},
author = {Gupta, Chirag and Suggala, Arun Sai and Goyal, Ankit and Simhadri, Harsha Vardhan and Paranjape, Bhargavi and Kumar, Ashish and Goya, Saurabh and Udupa, Raghavendra and Varma, Manik and Jain, Prateek},
isbn = {9781510855144},
journal = {34th Int. Conf. Mach. Learn. ICML 2017},
pages = {2144--2159},
title = {{ProtoNN: Compressed and accurate kNN for resource-scarce devices}},
volume = {3},
year = {2017}
}
@article{Kusupati2018,
abstract = {This paper develops the FastRNN and FastGRNN algorithms to address the twin RNN limitations of inaccurate training and inefficient prediction. Previous approaches have improved accuracy at the expense of prediction costs making them infeasible for resource-constrained and real-time applications. Unitary RNNs have increased accuracy somewhat by restricting the range of the state transition matrix's singular values but have also increased the model size as they require a larger number of hidden units to make up for the loss in expressive power. Gated RNNs have obtained state-of-the-art accuracies by adding extra parameters thereby resulting in even larger models. FastRNN addresses these limitations by adding a residual connection that does not constrain the range of the singular values explicitly and has only two extra scalar parameters. FastGRNN then extends the residual connection to a gate by reusing the RNN matrices to match state-of-the-art gated RNN accuracies but with a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse and quantized resulted in accurate models that could be up to 35x smaller than leading gated and unitary RNNs. This allowed FastGRNN to accurately recognize the "Hey Cortana" wakeword with a 1 KB model and to be deployed on severely resource-constrained IoT microcontrollers too tiny to store other RNN models. FastGRNN's code is available at https://github.com/Microsoft/EdgeML/.},
author = {Kusupati, Aditya and Singh, Manish and Bhatia, Kush and Kumar, Ashish and Jain, Prateek and Varma, Manik},
file = {::},
issn = {10495258},
journal = {Adv. Neural Inf. Process. Syst.},
number = {NeurIPS},
pages = {9017--9028},
title = {{FastgRNN: A fast, accurate, stable and tiny kilobyte sized gated recurrent neural network}},
volume = {2018-Decem},
year = {2018}
}
@article{Bakshy2018a,
abstract = {We describe AE, a machine learning platform for adaptive experimentation (e.g., Bayesian optimization, bandit optimization) that automates the process of sequential experimentation. Unlike existing solutions that are oriented primarily towards optimizing ML hyperparameters and simulations, AE is designed with online experimentation (A/B tests) in mind. Motivated by real-world examples from Facebook, we present a design for ML-assisted experimentation with multiple objectives, noisy, non-stationary measurements, and data from multiple experimentation modalities.},
author = {Bakshy, Eytan and Dworkin, Lili and Karrer, Brian and Kashin, Konstantin and Letham, Benjamin and Murthy, Ashwin and Singh, Shaun},
file = {::},
journal = {Conf. Neural Inf. Process. Syst.},
pages = {1--8},
title = {{AE: A domain-agnostic platform for adaptive experimentation}},
url = {http://learningsys.org/nips18/assets/papers/87CameraReadySubmissionAE - NeurIPS 2018.pdf},
year = {2018}
}
@article{Hughes2017,
abstract = {Deep learning approaches have been used to perform classification in several applications with high-dimensional input data. In this paper, we investigate the potential for deep learning for classifying affective touch on robotic skin in a social setting. Three models are considered, a convolutional neural network, a convolutional-recurrent neural network and an autoencoder-recurrent neural network. These models are evaluated on two publicly available affective touch datasets, and compared with models built to classify the same datasets. The deep learning approaches provide a similar level of accuracy, and allows gestures to be predicted in real-time at a rate of 6 to 9 Hertz. The memory requirements of the models demonstrate that they can be implemented on small, inexpensive microcontrollers, demonstrating that classification can be performed in the skin itself by collocating computing elements with the sensor array.},
author = {Hughes, Dana and Krauthammer, Alon and Correli, Nikolaus},
doi = {10.1109/ICRA.2017.7989267},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hughes, Krauthammer, Correli - 2017 - Recognizing social touch gestures using recurrent and convolutional neural networks.pdf:pdf},
isbn = {9781509046331},
issn = {10504729},
journal = {Proc. - IEEE Int. Conf. Robot. Autom.},
keywords = {Social Human-Robot Interaction,Physical Human-Robo},
pages = {2315--2321},
title = {{Recognizing social touch gestures using recurrent and convolutional neural networks}},
year = {2017}
}
@article{Han2015,
abstract = {Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce "deep compression", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency.},
archivePrefix = {arXiv},
arxivId = {1510.00149},
author = {Han, Song and Mao, Huizi and Dally, William J.},
eprint = {1510.00149},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Mao, Dally - 2015 - Deep Compression Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding(2).pdf:pdf},
pages = {1--14},
title = {{Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding}},
url = {http://arxiv.org/abs/1510.00149},
year = {2015}
}
@article{Liu2018g,
abstract = {Network pruning is widely used for reducing the heavy inference cost of deep models in low-resource settings. A typical pruning algorithm is a three-stage pipeline, i.e., training (a large model), pruning and fine-tuning. During pruning, according to a certain criterion, redundant weights are pruned and important weights are kept to best preserve the accuracy. In this work, we make several surprising observations which contradict common beliefs. For all state-of-the-art structured pruning algorithms we examined, fine-tuning a pruned model only gives comparable or worse performance than training that model with randomly initialized weights. For pruning algorithms which assume a predefined target network architecture, one can get rid of the full pipeline and directly train the target network from scratch. Our observations are consistent for multiple network architectures, datasets, and tasks, which imply that: 1) training a large, over-parameterized model is often not necessary to obtain an efficient final model, 2) learned "important" weights of the large model are typically not useful for the small pruned model, 3) the pruned architecture itself, rather than a set of inherited "important" weights, is more crucial to the efficiency in the final model, which suggests that in some cases pruning can be useful as an architecture search paradigm. Our results suggest the need for more careful baseline evaluations in future research on structured pruning methods. We also compare with the "Lottery Ticket Hypothesis" (Frankle {\&} Carbin 2019), and find that with optimal learning rate, the "winning ticket" initialization as used in Frankle {\&} Carbin (2019) does not bring improvement over random initialization.},
archivePrefix = {arXiv},
arxivId = {1810.05270},
author = {Liu, Zhuang and Sun, Mingjie and Zhou, Tinghui and Huang, Gao and Darrell, Trevor},
eprint = {1810.05270},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2018 - Rethinking the Value of Network Pruning.pdf:pdf},
pages = {1--21},
title = {{Rethinking the Value of Network Pruning}},
url = {http://arxiv.org/abs/1810.05270},
year = {2018}
}
@article{Albawi2018,
abstract = {Recently, social touch gesture recognition has been considered an important topic for touch modality, which can lead to highly efficient and realistic human-robot interaction. In this paper, a deep convolutional neural network is selected to implement a social touch recognition system for raw input samples (sensor data) only. The touch gesture recognition is performed using a dataset previously measured with numerous subjects that perform varying social gestures. This dataset is dubbed as the corpus of social touch, where touch was performed on a mannequin arm. A leave-one-subject-out cross-validation method is used to evaluate system performance. The proposed method can recognize gestures in nearly real time after acquiring a minimum number of frames (the average range of frame length was from 0.2{\%} to 4.19{\%} from the original frame lengths) with a classification accuracy of 63.7{\%}. The achieved classification accuracy is competitive in terms of the performance of existing algorithms. Furthermore, the proposed system outperforms other classification algorithms in terms of classification ratio and touch recognition time without data preprocessing for the same dataset.},
author = {Albawi, Saad and Bayat, Oguz and Al-Azawi, Saad and Ucan, Osman N.},
doi = {10.1155/2018/6973103},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Albawi et al. - 2018 - Social touch gesture recognition using convolutional neural network.pdf:pdf},
issn = {16875273},
journal = {Comput. Intell. Neurosci.},
title = {{Social touch gesture recognition using convolutional neural network}},
volume = {2018},
year = {2018}
}
@article{Frazier2018,
abstract = {Bayesian optimization is an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate. It is best-suited for optimization over continuous domains of less than 20 dimensions, and tolerates stochastic noise in function evaluations. It builds a surrogate for the objective and quantifies the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function defined from this surrogate to decide where to sample. In this tutorial, we describe how Bayesian optimization works, including Gaussian process regression and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. We then discuss more advanced techniques, including running multiple function evaluations in parallel, multi-fidelity and multi-information source optimization, expensive-to-evaluate constraints, random environmental conditions, multi-task Bayesian optimization, and the inclusion of derivative information. We conclude with a discussion of Bayesian optimization software and future research directions in the field. Within our tutorial material we provide a generalization of expected improvement to noisy evaluations, beyond the noise-free setting where it is more commonly applied. This generalization is justified by a formal decision-theoretic argument, standing in contrast to previous ad hoc modifications.},
archivePrefix = {arXiv},
arxivId = {1807.02811},
author = {Frazier, Peter I.},
eprint = {1807.02811},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frazier - 2018 - A Tutorial on Bayesian Optimization.pdf:pdf},
number = {Section 5},
pages = {1--22},
title = {{A Tutorial on Bayesian Optimization}},
url = {http://arxiv.org/abs/1807.02811},
year = {2018}
}
@article{Swersky2018,
abstract = {This paper considers the problem of simultaneously identifying the optima for a (continuous or discrete) set of correlated tasks, where the performance of a particular input parameter on a particular task can only be estimated from (potentially noisy) samples. This has many applications, for example, identifying a stochastic algorithm's optimal parameter settings for various tasks described by continuous feature values. We adapt the framework of Bayesian Optimisation to this problem. We propose a general multi-task optimisation framework and two myopic sampling procedures that determine task and parameter values for sampling, in order to efficiently find the best parameter setting for all tasks simultaneously. We show experimentally that our methods are much more efficient than collecting information randomly, and also more efficient than two other Bayesian multi-task optimisation algorithms from the literature.},
author = {Swersky, Kevin and Adams, Ryan P. and Snoek, Jasper and Adams, Ryan P.},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Swersky et al. - 2018 - Multi-Task Bayesian Optimization Kevin.pdf:pdf},
journal = {Eur. J. Oper. Res.},
keywords = {Global optimisation,Heuristics,Multi-task optimisation,Parameter tuning},
number = {3},
pages = {1074--1085},
title = {{Multi-Task Bayesian Optimization}},
volume = {270},
year = {2018}
}
@article{Wang2015,
abstract = {We study the problem of reducing test-time acquisition costs in classification systems. Our goal is to learn decision rules that adaptively select sensors for each example as necessary to make a confident prediction. We model our system as a directed acyclic graph (DAG) where internal nodes correspond to sensor subsets and decision functions at each node choose whether to acquire a new sensor or classify using the available measurements. This problem can be posed as an empirical risk minimization over training data. Rather than jointly optimizing such a highly coupled and non-convex problem over all decision nodes, we propose an efficient algorithm motivated by dynamic programming. We learn node policies in the DAG by reducing the global objective to a series of cost sensitive learning problems. Our approach is computationally efficient and has proven guarantees of convergence to the optimal system for a fixed architecture. In addition, we present an extension to map other budgeted learning problems with large number of sensors to our DAG architecture and demonstrate empirical performance exceeding state-of-the-art algorithms for data composed of both few and many sensors.},
author = {Wang, Joseph and Trapeznikov, Kirill and Saligrama, Venkatesh},
issn = {10495258},
journal = {Adv. Neural Inf. Process. Syst.},
pages = {2152--2160},
title = {{Efficient learning by directed acyclic graph for resource constrained prediction}},
volume = {2015-Janua},
year = {2015}
}
@article{Henderson2018,
abstract = {In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress. Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep RL more reproducible. We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted.},
archivePrefix = {arXiv},
arxivId = {arXiv:1709.06560v3},
author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
eprint = {arXiv:1709.06560v3},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henderson et al. - 2018 - Deep reinforcement learning that matters.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conf. Artif. Intell. AAAI 2018},
pages = {3207--3214},
title = {{Deep reinforcement learning that matters}},
year = {2018}
}
@article{Jose2013,
abstract = {Our objective is to speed up non-linear SVM prediction while maintaining classification accuracy above an acceptable limit. We generalize Localized Multiple Kernel Learning so as to learn a tree-based primal feature embedding which is high dimensional and sparse. Primal based classification decouples prediction costs from the number of support vectors and our tree-structured features efficiently encode non-linearities while speeding up prediction exponentially over the state-of-the-art. We develop routines for optimizing over the space of tree-structured features and efficiently scale to problems with more than half a million training points. Experiments on benchmark data sets reveal that our formulation can reduce prediction costs by more than three orders of magnitude in some cases with a moderate sacrifice in classification accuracy as compared to RBF-SVMs. Furthermore, our formulation leads to better classification accuracies over leading methods. Copyright 2013 by the author(s).},
author = {Jose, Cijo and Goyal, Prasoon and Aggrwal, Parv and Varma, Manik},
file = {:home/kostal/Downloads/jose13.pdf:pdf},
journal = {30th Int. Conf. Mach. Learn. ICML 2013},
number = {PART 2},
pages = {1523--1531},
title = {{Local deep kernel learning for efficient non-linear SVM prediction}},
volume = {28},
year = {2013}
}
@article{Snoek2015,
abstract = {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.},
archivePrefix = {arXiv},
arxivId = {1502.05700},
author = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md. Mostofa Ali and Prabhat and Adams, Ryan P.},
eprint = {1502.05700},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Snoek et al. - 2015 - Scalable Bayesian Optimization Using Deep Neural Networks.pdf:pdf},
title = {{Scalable Bayesian Optimization Using Deep Neural Networks}},
url = {http://arxiv.org/abs/1502.05700},
year = {2015}
}
@article{Nan2015,
abstract = {We seek decision rules for prediction-time cost reduction, where complete data is available for training, but during prediction-time, each feature can only be acquired for an additional cost. We propose a novel random forest algorithm to minimize prediction error for a user-specified average feature acquisition budget. While random forests yield strong generalization performance, they do not explicitly account for feature costs and furthermore require low correlation among trees, which amplifies costs. Our random forest grows trees with low acquisition cost and high strength based on greedy minimax cost-weighted-impurity splits. Theoretically, we establish near-optimal acquisition cost guarantees for our algorithm. Empirically, on a number of benchmark datasets we demonstrate competitive accuracy-cost curves against state-of-the-art prediction-time algorithms.},
archivePrefix = {arXiv},
arxivId = {1502.05925},
author = {Nan, Feng and Wang, Joseph and Saligrama, Venkatesh},
eprint = {1502.05925},
isbn = {9781510810587},
journal = {32nd Int. Conf. Mach. Learn. ICML 2015},
pages = {1983--1991},
title = {{Feature-budgeted random forest}},
volume = {3},
year = {2015}
}
@article{Elsken2019b,
abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
archivePrefix = {arXiv},
arxivId = {arXiv:1808.05377v3},
author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
doi = {10.1007/978-3-030-05318-5_3},
eprint = {arXiv:1808.05377v3},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elsken, Metzen, Hutter - 2019 - Neural Architecture Search.pdf:pdf},
keywords = {autodl,automl,neural architecture search,performance estimation strategy,search,search space design,strategy},
pages = {63--77},
title = {{Neural Architecture Search}},
volume = {20},
year = {2019}
}
@article{Baker2016,
abstract = {At present, designing convolutional neural network (CNN) architectures requires both human expertise and labor. New architectures are handcrafted by careful experimentation or modified from a handful of existing networks. We introduce MetaQNN, a meta-modeling algorithm based on reinforcement learning to automatically generate high-performing CNN architectures for a given learning task. The learning agent is trained to sequentially choose CNN layers using {\$}Q{\$}-learning with an {\$}\backslashepsilon{\$}-greedy exploration strategy and experience replay. The agent explores a large but finite space of possible architectures and iteratively discovers designs with improved performance on the learning task. On image classification benchmarks, the agent-designed networks (consisting of only standard convolution, pooling, and fully-connected layers) beat existing networks designed with the same layer types and are competitive against the state-of-the-art methods that use more complex layer types. We also outperform existing meta-modeling approaches for network design on image classification tasks.},
archivePrefix = {arXiv},
arxivId = {1611.02167},
author = {Baker, Bowen and Gupta, Otkrist and Naik, Nikhil and Raskar, Ramesh},
eprint = {1611.02167},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker et al. - 2016 - Designing Neural Network Architectures using Reinforcement Learning.pdf:pdf},
pages = {1--18},
title = {{Designing Neural Network Architectures using Reinforcement Learning}},
url = {http://arxiv.org/abs/1611.02167},
year = {2016}
}
@article{Loni2020,
abstract = {Deep Neural Networks (DNNs) are compute-intensive learning models with growing applicability in a wide range of domains. Due to their computational complexity, DNNs benefit from implementations that utilize custom hardware accelerators to meet performance and response time as well as classification accuracy constraints. In this paper, we propose DeepMaker framework that aims to automatically design a set of highly robust DNN architectures for embedded devices as the closest processing unit to the sensors. DeepMaker explores and prunes the design space to find improved neural architectures. Our proposed framework takes advantage of a multi-objective evolutionary approach that exploits a pruned design space inspired by a dense architecture. DeepMaker considers the accuracy along with the network size factor as two objectives to build a highly optimized network fitting with limited computational resource budgets while delivers an acceptable accuracy level. In comparison with the best result on the CIFAR-10 dataset, a generated network by DeepMaker presents up to a 26.4x compression rate while loses only 4{\%} accuracy. Besides, DeepMaker maps the generated CNN on the programmable commodity devices, including ARM Processor, High-Performance CPU, GPU, and FPGA.},
author = {Loni, Mohammad and Sinaei, Sima and Zoljodi, Ali and Daneshtalab, Masoud and Sj{\"{o}}din, Mikael},
doi = {10.1016/j.micpro.2020.102989},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loni et al. - 2020 - DeepMaker A multi-objective optimization framework for deep neural networks in embedded systems.pdf:pdf},
issn = {01419331},
journal = {Microprocess. Microsyst.},
keywords = {Convolutional Neural Networks (CNNs),Design Space Exploration (DSE),Embedded systems,Multi-Objective Optimization (MOO)},
pages = {102989},
publisher = {Elsevier B.V.},
title = {{DeepMaker: A multi-objective optimization framework for deep neural networks in embedded systems}},
url = {https://doi.org/10.1016/j.micpro.2020.102989},
volume = {73},
year = {2020}
}
@article{Bergstra2015,
abstract = {{\textcopyright} 2015 IOP Publishing Ltd. Sequential model-based optimization (also known as Bayesian optimization) is one of the most efficient methods (per function evaluation) of function minimization. This efficiency makes it appropriate for optimizing the hyperparameters of machine learning algorithms that are slow to train. The Hyperopt library provides algorithms and parallelization infrastructure for performing hyperparameter optimization (model selection) in Python. This paper presents an introductory tutorial on the usage of the Hyperopt library, including the description of search spaces, minimization (in serial and parallel), and the analysis of the results collected in the course of minimization. This paper also gives an overview of Hyperopt-Sklearn, a software project that provides automatic algorithm configuration of the Scikit-learn machine learning library. Following Auto-Weka, we take the view that the choice of classifier and even the choice of preprocessing module can be taken together to represent a single large hyperparameter optimization problem. We use Hyperopt to define a search space that encompasses many standard components (e.g. SVM, RF, KNN, PCA, TFIDF) and common patterns of composing them together. We demonstrate, using search algorithms in Hyperopt and standard benchmarking data sets (MNIST, 20-newsgroups, convex shapes), that searching this space is practical and effective. In particular, we improve on best-known scores for the model space for both MNIST and convex shapes. The paper closes with some discussion of ongoing and future work.},
author = {Bergstra, James and Komer, Brent and Eliasmith, Chris and Yamins, Dan and Cox, David D.},
doi = {10.1088/1749-4699/8/1/014008},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergstra et al. - 2015 - Hyperopt A Python library for model selection and hyperparameter optimization.pdf:pdf},
issn = {17494699},
journal = {Comput. Sci. Discov.},
keywords = {Bayesian optimization,Python,Scikit-learn,machine learning},
number = {1},
title = {{Hyperopt: A Python library for model selection and hyperparameter optimization}},
volume = {8},
year = {2015}
}
@article{Liu2017a,
abstract = {We explore efficient neural architecture search methods and show that a simple yet powerful evolutionary algorithm can discover new architectures with excellent performance. Our approach combines a novel hierarchical genetic representation scheme that imitates the modularized design pattern commonly adopted by human experts, and an expressive search space that supports complex topologies. Our algorithm efficiently discovers architectures that outperform a large number of manually designed models for image classification, obtaining top-1 error of 3.6{\%} on CIFAR-10 and 20.3{\%} when transferred to ImageNet, which is competitive with the best existing neural architecture search approaches. We also present results using random search, achieving 0.3{\%} less top-1 accuracy on CIFAR-10 and 0.1{\%} less on ImageNet whilst reducing the search time from 36 hours down to 1 hour.},
archivePrefix = {arXiv},
arxivId = {1711.00436},
author = {Liu, Hanxiao and Simonyan, Karen and Vinyals, Oriol and Fernando, Chrisantha and Kavukcuoglu, Koray},
eprint = {1711.00436},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2017 - Hierarchical Representations for Efficient Architecture Search.pdf:pdf},
pages = {1--13},
title = {{Hierarchical Representations for Efficient Architecture Search}},
url = {http://arxiv.org/abs/1711.00436},
year = {2017}
}
@article{L,
author = {{Le Cun}, Yann and Denker, John S. and Solla, Sara A.},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le Cun, Denker, Solla - Unknown - Optimal Brin Damage.pdf:pdf},
number = {c},
pages = {2--6},
title = {{Optimal Brain Damage}},
url = {http://yann.lecun.com/exdb/publis/pdf/lecun-90b.pdf},
volume = {1}
}
@article{Paria2018,
abstract = {Many real world applications can be framed as multi-objective optimization problems, where we wish to simultaneously optimize for multiple criteria. Bayesian optimization techniques for the multi-objective setting are pertinent when the evaluation of the functions in question are expensive. Traditional methods for multi-objective optimization, both Bayesian and otherwise, are aimed at recovering the Pareto front of these objectives. However, in certain cases a practitioner might desire to identify Pareto optimal points only in a subset of the Pareto front due to external considerations. In this work, we propose a strategy based on random scalarizations of the objectives that addresses this problem. Our approach is able to flexibly sample from desired regions of the Pareto front and, computationally, is considerably cheaper than most approaches for MOO. We also study a notion of regret in the multi-objective setting and show that our strategy achieves sublinear regret. We experiment with both synthetic and real-life problems, and demonstrate superior performance of our proposed algorithm in terms of the flexibility and regret.},
archivePrefix = {arXiv},
arxivId = {1805.12168},
author = {Paria, Biswajit and Kandasamy, Kirthevasan and P{\'{o}}czos, Barnab{\'{a}}s},
eprint = {1805.12168},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paria, Kandasamy, P{\'{o}}czos - 2018 - A Flexible Framework for Multi-Objective Bayesian Optimization using Random Scalarizations.pdf:pdf},
title = {{A Flexible Framework for Multi-Objective Bayesian Optimization using Random Scalarizations}},
url = {http://arxiv.org/abs/1805.12168},
year = {2018}
}
@article{Bergstra2012,
author = {Bergstra, James and Bengio, Yoshua},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergstra, Bengio - 2012 - 2012Bergstra{\_}RandomSearchForHyperParameterOptimization.pdf.pdf:pdf},
keywords = {deep learning,global optimization,model selection,neural networks,response surface},
pages = {281--305},
title = {{Random Search For HyperParameter Optimization}},
volume = {13},
year = {2012}
}
@article{Li2018n,
abstract = {As the backbone technology of machine learning, deep neural networks (DNNs) have have quickly ascended to the spotlight. Running DNNs on resource-constrained mobile devices is, however, by no means trivial, since it incurs high performance and energy overhead. While offloading DNNs to the cloud for execution suffers unpredictable performance, due to the uncontrolled long wide-area network latency. To address these challenges, in this paper, we propose Edgent, a collaborative and on-demand DNN co-inference framework with device-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that adaptively partitions DNN computation between device and edge, in order to leverage hybrid computation resources in proximity for real-time DNN inference. (2) DNN right-sizing that accelerates DNN inference through early-exit at a proper intermediate DNN layer to further reduce the computation latency. The prototype implementation and extensive evaluations based on Raspberry Pi demonstrate Edgent's effectiveness in enabling on-demand low-latency edge intelligence.},
archivePrefix = {arXiv},
arxivId = {arXiv:1806.07840v1},
author = {Li, En and Zhou, Zhi and Chen, Xu},
doi = {10.1145/3229556.3229562},
eprint = {arXiv:1806.07840v1},
file = {:home/kostal/Downloads/1806.07840v1.pdf:pdf},
isbn = {9781450359061},
journal = {MECOMM 2018 - Proc. 2018 Work. Mob. Edge Commun. Part SIGCOMM 2018},
keywords = {Computation offloading,Deep learning,Edge computing,Edge intelligence},
pages = {31--36},
title = {{Edge intelligence: On-demand deep learning model co-inference with device-edge synergy}},
year = {2018}
}
@article{Mockus1978,
abstract = {The purpose of this paper is to describe how the Bayesian approach can be applied ot the global optimization of multiextremal functions. The function to be minimized is considered as a realizatin of some stochastic function. The optimization technique based upon the minimization of the expected deviation from the extremum is called Bayesian. The implementation of Bayesian methods is considered. The results of the application to the minimization of some standard test functions are given.},
author = {Mockus, Jonas and Tiesis, Vytautas and Zilinskas, Antanas},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mockus, Tiesis, Zilinskas - 1978 - The application of Bayesian methods for seeking the extremum.pdf:pdf},
isbn = {9781479932795},
journal = {Towar. Glob. Optim.},
keywords = {Expected Improvement},
number = {September 2014},
pages = {117--129},
title = {{The application of Bayesian methods for seeking the extremum}},
volume = {2},
year = {1978}
}
@article{Wistuba2019,
abstract = {The growing interest in both the automation of machine learning and deep learning has inevitably led to the development of a wide variety of automated methods for neural architecture search. The choice of the network architecture has proven to be critical, and many advances in deep learning spring from its immediate improvements. However, deep learning techniques are computationally intensive and their application requires a high level of domain knowledge. Therefore, even partial automation of this process helps to make deep learning more accessible to both researchers and practitioners. With this survey, we provide a formalism which unifies and categorizes the landscape of existing methods along with a detailed analysis that compares and contrasts the different approaches. We achieve this via a comprehensive discussion of the commonly adopted architecture search spaces and architecture optimization algorithms based on principles of reinforcement learning and evolutionary algorithms along with approaches that incorporate surrogate and one-shot models. Additionally, we address the new research directions which include constrained and multi-objective architecture search as well as automated data augmentation, optimizer and activation function search.},
archivePrefix = {arXiv},
arxivId = {1905.01392},
author = {Wistuba, Martin and Rawat, Ambrish and Pedapati, Tejaswini},
eprint = {1905.01392},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wistuba, Rawat, Pedapati - 2019 - A Survey on Neural Architecture Search.pdf:pdf},
keywords = {automation of machine learning,constrained optimization,deep learn-,evolutionary algorithms,ing,multi-,neural architecture search,objective optimization,reinforcement learning},
title = {{A Survey on Neural Architecture Search}},
url = {http://arxiv.org/abs/1905.01392},
year = {2019}
}
@article{Wu2018,
abstract = {Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too expensive for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets, a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1{\%} top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4x smaller and 1.5x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5{\%} to 6.4{\%} higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2{\%} accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4x speedup on an iPhone X.},
archivePrefix = {arXiv},
arxivId = {1812.03443},
author = {Wu, Bichen and Dai, Xiaoliang and Zhang, Peizhao and Wang, Yanghan and Sun, Fei and Wu, Yiming and Tian, Yuandong and Vajda, Peter and Jia, Yangqing and Keutzer, Kurt},
eprint = {1812.03443},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2018 - FBNet Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search.pdf:pdf},
title = {{FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search}},
url = {http://arxiv.org/abs/1812.03443},
year = {2018}
}
@article{K.O.2002,
abstract = {An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolu-tion of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incremen-tally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is significantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.},
author = {K.O., Stanley and R., Miikkulainen},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/K.O., R. - 2002 - Evolving neural networks through augmenting topologies.pdf:pdf},
journal = {Evol. Comput.},
keywords = {competing conventions,genetic algorithms,network topologies,neural networks,neuroevolution,speciation},
number = {2},
pages = {99--127},
title = {{Evolving neural networks through augmenting topologies}},
url = {http://mitpress.mit.edu/e-mail},
volume = {10},
year = {2002}
}
@article{Rotem2018,
abstract = {This paper presents the design of Glow, a machine learning compiler for heterogeneous hardware. It is a pragmatic approach to compilation that enables the generation of highly optimized code for multiple targets. Glow lowers the traditional neural network dataflow graph into a two-phase strongly-typed intermediate representation. The high-level intermediate representation allows the optimizer to perform domain-specific optimizations. The lower-level instruction-based address-only intermediate representation allows the compiler to perform memory-related optimizations, such as instruction scheduling, static memory allocation and copy elimination. At the lowest level, the optimizer performs machine-specific code generation to take advantage of specialized hardware features. Glow features a lowering phase which enables the compiler to support a high number of input operators as well as a large number of hardware targets by eliminating the need to implement all operators on all targets. The lowering phase is designed to reduce the input space and allow new hardware backends to focus on a small number of linear algebra primitives.},
archivePrefix = {arXiv},
arxivId = {1805.00907},
author = {Rotem, Nadav and Fix, Jordan and Abdulrasool, Saleem and Catron, Garret and Deng, Summer and Dzhabarov, Roman and Gibson, Nick and Hegeman, James and Lele, Meghan and Levenstein, Roman and Montgomery, Jack and Maher, Bert and Nadathur, Satish and Olesen, Jakob and Park, Jongsoo and Rakhov, Artem and Smelyanskiy, Misha and Wang, Man},
eprint = {1805.00907},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rotem et al. - 2018 - Glow Graph Lowering Compiler Techniques for Neural Networks.pdf:pdf},
title = {{Glow: Graph Lowering Compiler Techniques for Neural Networks}},
url = {http://arxiv.org/abs/1805.00907},
year = {2018}
}
@article{Tan2018,
abstract = {Designing convolutional neural networks (CNN) for mobile devices is challenging because mobile models need to be small and fast, yet still accurate. Although significant efforts have been dedicated to design and improve mobile CNNs on all dimensions, it is very difficult to manually balance these trade-offs when there are so many architectural possibilities to consider. In this paper, we propose an automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency. Unlike previous work, where latency is considered via another, often inaccurate proxy (e.g., FLOPS), our approach directly measures real-world inference latency by executing the model on mobile phones. To further strike the right balance between flexibility and search space size, we propose a novel factorized hierarchical search space that encourages layer diversity throughout the network. Experimental results show that our approach consistently outperforms state-of-the-art mobile CNN models across multiple vision tasks. On the ImageNet classification task, our MnasNet achieves 75.2{\%} top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8x faster than MobileNetV2 [29] with 0.5{\%} higher accuracy and 2.3x faster than NASNet [36] with 1.2{\%} higher accuracy. Our MnasNet also achieves better mAP quality than MobileNets for COCO object detection. Code is at https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet},
archivePrefix = {arXiv},
arxivId = {1807.11626},
author = {Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V.},
eprint = {1807.11626},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan et al. - 2018 - MnasNet Platform-Aware Neural Architecture Search for Mobile.pdf:pdf},
title = {{MnasNet: Platform-Aware Neural Architecture Search for Mobile}},
url = {http://arxiv.org/abs/1807.11626},
year = {2018}
}
@article{Jung2017,
abstract = {For an artifact such as a robot or a virtual agent to respond appropriately to human social touch behavior, it should be able to automatically detect and recognize touch. This paper describes the data collection of CoST: Corpus of Social Touch, a data set containing 7805 captures of 14 different social touch gestures. All touch gestures were performed in three variants: gentle, normal and rough on a pressure sensor grid wrapped around a mannequin arm. Recognition of these 14 gesture classes using various classifiers yielded accuracies up to 60Â {\%}; moreover, gentle gestures proved to be harder to classify than normal and rough gestures. We further investigated how different classifiers, interpersonal differences, gesture confusions and gesture variants affected the recognition accuracy. Finally, we present directions for further research to ensure proper transfer of the touch modality from interpersonal interaction to areas such as humanâ€“robot interaction (HRI).},
author = {Jung, Merel M. and Poel, Mannes and Poppe, Ronald and Heylen, Dirk K.J.},
doi = {10.1007/s12193-016-0232-9},
issn = {17838738},
journal = {J. Multimodal User Interfaces},
keywords = {Social touch,Touch corpus,Touch gesture recognition},
number = {1},
pages = {81--96},
publisher = {Springer International Publishing},
title = {{Automatic recognition of touch gestures in the corpus of social touch}},
volume = {11},
year = {2017}
}
@article{Garrido-Merchan2018,
abstract = {Bayesian Optimization (BO) methods are useful for optimizing functions that are expen- sive to evaluate, lack an analytical expression and whose evaluations can be contaminated by noise. These methods rely on a probabilistic model of the objective function, typically a Gaussian process (GP), upon which an acquisition function is built. The acquisition function guides the optimization process and measures the expected utility of performing an evaluation of the objective at a new point. GPs assume continous input variables. When this is not the case, for example when some of the input variables take categorical or integer values, one has to introduce extra approximations. Consider a suggested input location taking values in the real line. Before doing the evaluation of the objective, a common approach is to use a one hot encoding approximation for categorical variables, or to round to the closest integer, in the case of integer-valued variables. We show that this can lead to problems in the optimization process and describe a more principled approach to account for input variables that are categorical or integer-valued. We illustrate in both synthetic and a real experiments the utility of our approach, which significantly improves the results of standard BO methods using Gaussian processes on problems with categorical or integer-valued variables.},
archivePrefix = {arXiv},
arxivId = {1805.03463},
author = {Garrido-Merch{\'{a}}n, Eduardo C. and Hern{\'{a}}ndez-Lobato, Daniel},
eprint = {1805.03463},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garrido-Merch{\'{a}}n, Hern{\'{a}}ndez-Lobato - 2018 - Dealing with Categorical and Integer-valued Variables in Bayesian Optimization with Gaussia.pdf:pdf},
pages = {1--18},
title = {{Dealing with Categorical and Integer-valued Variables in Bayesian Optimization with Gaussian Processes}},
url = {http://arxiv.org/abs/1805.03463},
year = {2018}
}
@article{Ta2015a,
abstract = {New technologies and especially robotics is going towards more natural user interfaces. Works have been done in different modality of interaction such as sight (visual computing), and audio (speech and audio recognition) but some other modalities are still less researched. The touch modality is one of the less studied in HRI but could be valuable for naturalistic interaction. However touch signals can vary in semantics. It is therefore necessary to be able to recognize touch gestures in order to make human-robot interaction even more natural. We propose a method to recognize touch gestures. This method was developed on the CoST corpus and then directly applied on the HAART dataset as a participation of the Social Touch Challenge at ICMI 2015. Our touch gesture recognition process is detailed in this article to make it reproducible by other research teams. Besides features set description, we manually filtered the training corpus to produce 2 datasets. For the challenge, we submitted 6 different systems. A Support Vector Machine and a Random Forest classifiers for the HAART dataset. For the CoST dataset, the same classifiers are tested in two conditions: using all or filtered training datasets. As reported by organizers, our systems have the best correct rate in this year's challenge (70.91{\%} on HAART, 61.34{\%} on CoST). Our performances are slightly better that other participants but stay under previous reported state-of-the-art results.},
author = {Ta, Viet Cuong and Johal, Wafa and Portaz, Maxime and Castelli, Eric and Vaufreydaz, Dominique},
doi = {10.1145/2818346.2830598},
isbn = {9781450339124},
journal = {ICMI 2015 - Proc. 2015 ACM Int. Conf. Multimodal Interact.},
keywords = {Gesture recognition,Multimodal perception,Touch challenge},
number = {November},
pages = {391--398},
title = {{The grenoble system for the social touch challenge at ICMI 2015}},
year = {2015}
}
@article{Cai2019h,
abstract = {We address the challenging problem of efficient deep learning model deployment across many devices and diverse constraints, from general-purpose hardware to specialized accelerators. Conventional approaches either manually design or use neural architecture search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing {\$}CO{\_}2{\$} emission as much as 5 cars' lifetime) thus unscalable. To reduce the cost, our key idea is to decouple model training from architecture search. To this end, we propose to train a once-for-all network (OFA) that supports diverse architectural settings (depth, width, kernel size, and resolution). Given a deployment scenario, we can then quickly get a specialized sub-network by selecting from the OFA network without additional training. To prevent interference between many sub-networks during training, we also propose a novel progressive shrinking algorithm, which can train a surprisingly large number of sub-networks ({\$}{\textgreater} 10{\^{}}{\{}19{\}}{\$}) simultaneously. Extensive experiments on various hardware platforms (CPU, GPU, mCPU, mGPU, FPGA accelerator) show that OFA consistently outperforms SOTA NAS methods (up to 4.0{\%} ImageNet top1 accuracy improvement over MobileNetV3) while reducing orders of magnitude GPU hours and {\$}CO{\_}2{\$} emission. In particular, OFA achieves a new SOTA 80.0{\%} ImageNet top1 accuracy under the mobile setting ({\$}{\textless}{\$}600M FLOPs). Code and pre-trained models are released at https://github.com/mit-han-lab/once-for-all.},
archivePrefix = {arXiv},
arxivId = {1908.09791},
author = {Cai, Han and Gan, Chuang and Wang, Tianzhe and Zhang, Zhekai and Han, Song},
eprint = {1908.09791},
file = {:home/kostal/Downloads/1908.09791.pdf:pdf},
pages = {1--13},
title = {{Once-for-All: Train One Network and Specialize it for Efficient Deployment on Diverse Hardware Platforms}},
url = {http://arxiv.org/abs/1908.09791},
year = {2019}
}
@article{Hutter2013,
abstract = {We benchmark a sequential model-based optimization procedure, SMAC-BBOB, on the BBOB set of blackbox functions. We demonstrate that with a small budget of 10Ã—D evaluations of D-dimensional functions, SMAC-BBOB in most cases outperforms the state-of-the-art blackbox optimizer CMA-ES. However, CMA-ES benefits more from growing the budget to 100 Ã— D, and for larger number of function evaluations SMAC-BBOB also requires increasingly large computational resources for building and using its models.},
author = {Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
doi = {10.1145/2464576.2501592},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutter, Hoos, Leyton-Brown - 2013 - An evaluation of sequential model-based optimization for expensive blackbox functions.pdf:pdf},
isbn = {9781450319645},
keywords = {benchmarking,black-box optimization},
pages = {1209},
title = {{An evaluation of sequential model-based optimization for expensive blackbox functions}},
year = {2013}
}
@article{Frankle2019,
abstract = {Neural network pruning techniques can reduce the parameter counts of trained networks by over 90{\%}, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the lottery ticket hypothesis: dense, randomly-initialized, feed-forward networks contain subnetworks (winning tickets) that-when trained in isolation-reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20{\%} of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.},
archivePrefix = {arXiv},
arxivId = {1803.03635},
author = {Frankle, Jonathan and Carbin, Michael},
eprint = {1803.03635},
journal = {7th Int. Conf. Learn. Represent. ICLR 2019},
pages = {1--42},
title = {{The lottery ticket hypothesis: Finding sparse, trainable neural networks}},
year = {2019}
}
@article{Molchanov2017,
abstract = {We explore a recently proposed Variational Dropout technique that provided an elegant Bayesian interpretation to Gaussian Dropout. We extend Variational Dropout to the case when dropout rates are unbounded, propose a way to reduce the variance of the gradient estimator and report first experimental results with individual dropout rates per weight. Interestingly, it leads to extremely sparse solutions both in fully-connected and convolutional layers. This effect is similar to automatic relevance determination effect in empirical Bayes but has a number of advantages. We reduce the number of parameters up to 280 times on LeNet architectures and up to 68 times on VGG-like networks with a negligible decrease of accuracy.},
archivePrefix = {arXiv},
arxivId = {1701.05369},
author = {Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry},
eprint = {1701.05369},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Molchanov, Ashukha, Vetrov - 2017 - Variational Dropout Sparsifies Deep Neural Networks(3).pdf:pdf},
title = {{Variational Dropout Sparsifies Deep Neural Networks}},
url = {http://arxiv.org/abs/1701.05369},
year = {2017}
}
@article{Jiang2019,
abstract = {A fundamental question lies in almost every application of deep neural networks: what is the optimal neural architecture given a specific dataset? Recently, several Neural Architecture Search (NAS) frameworks have been developed that use reinforcement learning and evolutionary algorithm to search for the solution. However, most of them take a long time to find the optimal architecture due to the huge search space and the lengthy training process needed to evaluate each candidate. In addition, most of them aim at accuracy only and do not take into consideration the hardware that will be used to implement the architecture. This will potentially lead to excessive latencies beyond specifications, rendering the resulting architectures useless. To address both issues, in this paper we use Field Programmable Gate Arrays (FPGAs) as a vehicle to present a novel hardware-aware NAS framework, namely FNAS, which will provide an optimal neural architecture with latency guaranteed to meet the specification. In addition, with a performance abstraction model to analyze the latency of neural architectures without training, our framework can quickly prune architectures that do not satisfy the specification, leading to higher efficiency. Experimental results on common data set such as ImageNet show that in the cases where the state-of-the-art generates architectures with latencies 7.81x longer than the specification, those from FNAS can meet the specs with less than 1{\%} accuracy loss. Moreover, FNAS also achieves up to 11.13x speedup for the search process. To the best of the authors' knowledge, this is the very first hardware aware NAS.},
archivePrefix = {arXiv},
arxivId = {arXiv:1901.11211v1},
author = {Jiang, Weiwen and Zhang, Xinyi and Sha, Edwin H.M. and Yang, Lei and Zhuge, Qingfeng and Shi, Yiyu and Hu, Jingtong},
doi = {10.1145/3316781.3317757},
eprint = {arXiv:1901.11211v1},
file = {:home/kostal/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - 2019 - Accuracy vs. efficiency Achieving both through FPGA-implementation aware neural architecture search.pdf:pdf},
isbn = {9781450367257},
issn = {0738100X},
journal = {Proc. - Des. Autom. Conf.},
pages = {2--8},
title = {{Accuracy vs. efficiency: Achieving both through FPGA-implementation aware neural architecture search}},
volume = {5},
year = {2019}
}
@article{Wang2019a,
abstract = {Learning text representation is crucial for text classification and other language related tasks. There are a diverse set of text representation networks in the literature, and how to find the optimal one is a non-trivial problem. Recently, the emerging Neural Architecture Search (NAS) techniques have demonstrated good potential to solve the problem. Nevertheless, most of the existing works of NAS focus on the search algorithms and pay little attention to the search space. In this paper, we argue that the search space is also an important human prior to the success of NAS in different applications. Thus, we propose a novel search space tailored for text representation. Through automatic search, the discovered network architecture outperforms state-of-the-art models on various public datasets on text classification and natural language inference tasks. Furthermore, some of the design principles found in the automatic network agree well with human intuition.},
archivePrefix = {arXiv},
arxivId = {1912.10729},
author = {Wang, Yujing and Yang, Yaming and Chen, Yiren and Bai, Jing and Zhang, Ce and Su, Guinan and Kou, Xiaoyu and Tong, Yunhai and Yang, Mao and Zhou, Lidong},
eprint = {1912.10729},
file = {:home/kostal/Downloads/1912.10729.pdf:pdf},
title = {{TextNAS: A Neural Architecture Search Space tailored for Text Representation}},
url = {http://arxiv.org/abs/1912.10729},
year = {2019}
}
@article{Cai2019f,
abstract = {We address the challenging problem of efficient deep learning model deployment across many devices and diverse constraints, from general-purpose hardware to specialized accelerators. Conventional approaches either manually design or use neural architecture search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing {\$}CO{\_}2{\$} emission as much as 5 cars' lifetime) thus unscalable. To reduce the cost, our key idea is to decouple model training from architecture search. To this end, we propose to train a once-for-all network (OFA) that supports diverse architectural settings (depth, width, kernel size, and resolution). Given a deployment scenario, we can then quickly get a specialized sub-network by selecting from the OFA network without additional training. To prevent interference between many sub-networks during training, we also propose a novel progressive shrinking algorithm, which can train a surprisingly large number of sub-networks ({\$}{\textgreater} 10{\^{}}{\{}19{\}}{\$}) simultaneously. Extensive experiments on various hardware platforms (CPU, GPU, mCPU, mGPU, FPGA accelerator) show that OFA consistently outperforms SOTA NAS methods (up to 4.0{\%} ImageNet top1 accuracy improvement over MobileNetV3) while reducing orders of magnitude GPU hours and {\$}CO{\_}2{\$} emission. In particular, OFA achieves a new SOTA 80.0{\%} ImageNet top1 accuracy under the mobile setting ({\$}{\textless}{\$}600M FLOPs). Code and pre-trained models are released at https://github.com/mit-han-lab/once-for-all.},
archivePrefix = {arXiv},
arxivId = {1908.09791},
author = {Cai, Han and Gan, Chuang and Wang, Tianzhe and Zhang, Zhekai and Han, Song},
eprint = {1908.09791},
file = {:home/kostal/Downloads/1908.09791.pdf:pdf},
pages = {1--13},
title = {{Once-for-All: Train One Network and Specialize it for Efficient Deployment on Diverse Hardware Platforms}},
url = {http://arxiv.org/abs/1908.09791},
year = {2019}
}
@article{Deb2002,
abstract = {Multiobjective evolutionary algorithms (EAs) that use nondominated sorting and sharing have been criti- cized mainly for their: 1) (where is the number of objectives and @ QA computational complexity is the population size); 2) nonelitism approach; and 3) the need for specifying a sharing parameter. In this paper, we suggest a nondominated sorting-based multiobjective EA (MOEA), called nondominated sorting genetic algorithm II (NSGA-II), which alleviates all the above three difficulties. Specifically, a fast nondominated presented. Also, a selection operator is presented that creates a sorting approach with @ PA computational complexity is mating pool by combining the parent and offspring populations and selecting the best (with respect to fitness and spread) solutions. Simulation results on difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to Pareto-archived evolution strategy and strength-Pareto EAâ€”two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multiobjective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective seven-constraint nonlinear problem, are compared with another constrained multiobjective optimizer and much better performance of NSGA-II is observed},
author = {{Kalyanmoy Deb, Associate Member, IEEE, Amrit Pratap, Sameer Agarwal}, and T. Meyarivan},
doi = {10.1016/j.ejor.2017.07.027},
file = {::},
issn = {03772217},
journal = {IEEE Trans. Evol. Comput.},
keywords = {Genetic algorithms},
number = {2},
pages = {182--196},
title = {{A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II}},
volume = {6},
year = {2002}
}
